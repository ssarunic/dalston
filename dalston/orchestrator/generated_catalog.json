{
  "generated_at": "2026-02-17T14:16:05.932986+00:00",
  "schema_version": "1.1",
  "engine_count": 17,
  "engines": {
    "whisperx-align": {
      "id": "whisperx-align",
      "name": "WhisperX Alignment",
      "version": "1.0.0",
      "stage": "align",
      "type": null,
      "description": "Word-level timestamp alignment using WhisperX with wav2vec2-based\nforced alignment. Produces more accurate word boundaries than\ntranscription-time estimates.\n\nLoads language-specific alignment models lazily on first use.\nSupports 100+ languages via wav2vec2 models from HuggingFace.",
      "image": "dalston/stt-batch-align-whisperx-align:1.0.0",
      "capabilities": {
        "stages": [
          "align"
        ],
        "languages": null,
        "supports_word_timestamps": true,
        "supports_streaming": false,
        "max_audio_duration": 7200,
        "max_concurrency": 8
      },
      "hardware": {
        "gpu_required": false,
        "gpu_optional": true,
        "min_vram_gb": 2,
        "recommended_gpu": [
          "t4"
        ],
        "supports_cpu": true,
        "min_ram_gb": 4,
        "memory": "4G"
      },
      "performance": {
        "rtf_gpu": 0.02,
        "rtf_cpu": 0.3,
        "warm_start_latency_ms": 200
      },
      "hf_compat": {
        "pipeline_tag": "automatic-speech-recognition",
        "library_name": "whisperx",
        "license": "bsd-4-clause"
      },
      "input": {
        "audio_formats": [
          "wav"
        ],
        "sample_rate": 16000,
        "channels": 1
      }
    },
    "pii-presidio": {
      "id": "pii-presidio",
      "name": "PII Detection (Presidio + GLiNER)",
      "version": "1.0.0",
      "stage": "pii_detect",
      "type": null,
      "description": "Detects personally identifiable information using Microsoft Presidio\nwith GLiNER for ML-based entity recognition. Supports three detection\ntiers: fast (regex only), standard (+ GLiNER), thorough (+ LLM).",
      "image": "dalston/stt-batch-pii_detect-pii-presidio:1.0.0",
      "capabilities": {
        "stages": [
          "pii_detect"
        ],
        "languages": null,
        "supports_word_timestamps": false,
        "supports_streaming": false,
        "max_audio_duration": null,
        "max_concurrency": 8
      },
      "hardware": {
        "gpu_required": false,
        "gpu_optional": true,
        "min_vram_gb": 0,
        "recommended_gpu": null,
        "supports_cpu": true,
        "min_ram_gb": 4,
        "memory": "4G"
      },
      "performance": {
        "rtf_gpu": 0.01,
        "rtf_cpu": 0.05,
        "warm_start_latency_ms": 100
      },
      "hf_compat": {
        "pipeline_tag": "dalston:pii-redaction",
        "library_name": "presidio",
        "license": "mit"
      }
    },
    "pyannote-3.1": {
      "id": "pyannote-3.1",
      "name": "Pyannote Speaker Diarization 3.1",
      "version": "1.0.0",
      "stage": "diarize",
      "type": null,
      "description": "Speaker diarization using pyannote-audio 3.1.\nIdentifies who speaks when in an audio file.\n\nRequires HuggingFace token (HF_TOKEN) for accessing gated models.\nSupports optional min/max speaker count hints for improved accuracy.",
      "image": "dalston/stt-batch-diarize-pyannote-3.1:1.0.0",
      "capabilities": {
        "stages": [
          "diarize"
        ],
        "languages": null,
        "supports_word_timestamps": false,
        "supports_streaming": false,
        "max_audio_duration": 7200,
        "max_concurrency": 4
      },
      "hardware": {
        "gpu_required": false,
        "gpu_optional": true,
        "min_vram_gb": 2,
        "recommended_gpu": [
          "t4"
        ],
        "supports_cpu": true,
        "min_ram_gb": 6,
        "memory": "6G"
      },
      "performance": {
        "rtf_gpu": 0.1,
        "rtf_cpu": 1.5,
        "warm_start_latency_ms": 500
      },
      "hf_compat": {
        "pipeline_tag": "speaker-diarization",
        "library_name": "pyannote",
        "license": "mit"
      },
      "input": {
        "audio_formats": [
          "wav"
        ],
        "sample_rate": 16000,
        "channels": 1
      }
    },
    "pyannote-4.0": {
      "id": "pyannote-4.0",
      "name": "Pyannote Speaker Diarization 4.0",
      "version": "1.0.0",
      "stage": "diarize",
      "type": null,
      "description": "Speaker diarization using pyannote-audio 4.0 with the new Community-1 pipeline.\nIdentifies who speaks when in an audio file.\n\nNew in 4.0:\n  - VBx clustering for improved speaker counting and assignment\n  - Exclusive mode for single-speaker segments (better Whisper alignment)\n  - NumPy 2.0 and modern dependency compatibility\n\nRequires HuggingFace token (HF_TOKEN) for accessing gated models.\nSupports optional min/max speaker count hints for improved accuracy.",
      "image": "dalston/stt-batch-diarize-pyannote-4.0:1.0.0",
      "capabilities": {
        "stages": [
          "diarize"
        ],
        "languages": null,
        "supports_word_timestamps": false,
        "supports_streaming": false,
        "max_audio_duration": 7200,
        "max_concurrency": 4
      },
      "hardware": {
        "gpu_required": false,
        "gpu_optional": true,
        "min_vram_gb": 2,
        "recommended_gpu": [
          "t4"
        ],
        "supports_cpu": true,
        "min_ram_gb": 6,
        "memory": "6G"
      },
      "performance": {
        "rtf_gpu": 0.08,
        "rtf_cpu": 1.2,
        "warm_start_latency_ms": 500
      },
      "hf_compat": {
        "pipeline_tag": "speaker-diarization",
        "library_name": "pyannote",
        "license": "mit"
      },
      "input": {
        "audio_formats": [
          "wav"
        ],
        "sample_rate": 16000,
        "channels": 1
      }
    },
    "final-merger": {
      "id": "final-merger",
      "name": "Final Merger",
      "version": "1.1.0",
      "stage": "merge",
      "type": null,
      "description": "Combines outputs from upstream pipeline stages into the\nstandard Dalston transcript format.\n\nAdds segment IDs, metadata, and writes the canonical\ntranscript.json file for the Gateway to read.\n\nFor per_channel mode with PII detection and audio redaction:\n- Collects and merges PII entities from each channel\n- Assembles redacted mono WAVs into stereo output (FFmpeg)",
      "image": "dalston/stt-batch-merge-final-merger:1.1.0",
      "capabilities": {
        "stages": [
          "merge"
        ],
        "languages": null,
        "supports_word_timestamps": false,
        "supports_streaming": false,
        "max_audio_duration": 86400,
        "max_concurrency": 16
      },
      "hardware": {
        "gpu_required": false,
        "gpu_optional": false,
        "min_vram_gb": 0,
        "recommended_gpu": null,
        "supports_cpu": true,
        "min_ram_gb": 1,
        "memory": "256M"
      },
      "performance": {
        "rtf_gpu": null,
        "rtf_cpu": 0.001,
        "warm_start_latency_ms": 5
      },
      "hf_compat": {
        "pipeline_tag": "dalston:merge",
        "library_name": "python",
        "license": "apache-2.0"
      }
    },
    "audio-prepare": {
      "id": "audio-prepare",
      "name": "Audio Prepare",
      "version": "1.0.0",
      "stage": "prepare",
      "type": null,
      "description": "Converts any audio format to 16kHz, 16-bit, mono WAV.\nExtracts duration and audio metadata using ffprobe.\nRequired as the first stage of all batch pipelines.",
      "image": "dalston/stt-batch-prepare-audio-prepare:1.0.0",
      "capabilities": {
        "stages": [
          "prepare"
        ],
        "languages": null,
        "supports_word_timestamps": false,
        "supports_streaming": false,
        "max_audio_duration": 14400,
        "max_concurrency": 8
      },
      "hardware": {
        "gpu_required": false,
        "gpu_optional": false,
        "min_vram_gb": 0,
        "recommended_gpu": null,
        "supports_cpu": true,
        "min_ram_gb": 1,
        "memory": "512M"
      },
      "performance": {
        "rtf_gpu": null,
        "rtf_cpu": 0.1,
        "warm_start_latency_ms": 10
      },
      "hf_compat": {
        "pipeline_tag": "dalston:audio-preparation",
        "library_name": "ffmpeg",
        "license": "apache-2.0"
      },
      "input": {
        "audio_formats": [
          "mp3",
          "wav",
          "m4a",
          "flac",
          "ogg",
          "webm",
          "mp4",
          "mkv",
          "avi",
          "aac",
          "wma"
        ],
        "sample_rate": "any",
        "channels": "any"
      }
    },
    "faster-whisper-streaming-base": {
      "id": "faster-whisper-streaming-base",
      "name": "Faster Whisper Streaming Base",
      "version": "1.0.0",
      "stage": null,
      "type": "realtime",
      "description": "Real-time streaming transcription using faster-whisper (CTranslate2).\nSupports both \"fast\" (distil-whisper) and \"accurate\" (large-v3) model modes.\nUses Silero VAD for speech boundary detection.",
      "image": "dalston/stt-rt-faster-whisper-streaming-base:1.0.0",
      "capabilities": {
        "stages": [],
        "languages": null,
        "supports_word_timestamps": true,
        "supports_streaming": true,
        "max_audio_duration": null,
        "max_concurrency": 4
      },
      "hardware": {
        "gpu_required": false,
        "gpu_optional": true,
        "min_vram_gb": 6,
        "recommended_gpu": [
          "t4",
          "a10g"
        ],
        "supports_cpu": true,
        "min_ram_gb": 12,
        "memory": "12G"
      },
      "performance": {
        "rtf_gpu": 0.1,
        "rtf_cpu": 0.5,
        "warm_start_latency_ms": 200
      },
      "hf_compat": {
        "pipeline_tag": "automatic-speech-recognition",
        "library_name": "ctranslate2",
        "license": "mit"
      }
    },
    "parakeet-streaming-0.6b": {
      "id": "parakeet-streaming-0.6b",
      "name": "Parakeet Streaming 0.6B",
      "version": "1.0.0",
      "stage": null,
      "type": "realtime",
      "description": "Real-time streaming transcription using NVIDIA Parakeet 0.6B.\nUses cache-aware FastConformer encoder for true streaming with ~100ms latency.\nEnglish-only, requires NVIDIA GPU.",
      "image": "dalston/stt-rt-parakeet-streaming-0.6b:1.0.0",
      "capabilities": {
        "stages": [],
        "languages": [
          "en"
        ],
        "supports_word_timestamps": true,
        "supports_streaming": true,
        "max_audio_duration": null,
        "max_concurrency": 4
      },
      "hardware": {
        "gpu_required": true,
        "gpu_optional": false,
        "min_vram_gb": 4,
        "recommended_gpu": [
          "t4",
          "a10g"
        ],
        "supports_cpu": false,
        "min_ram_gb": 8,
        "memory": "6G"
      },
      "performance": {
        "rtf_gpu": 0.05,
        "rtf_cpu": null,
        "warm_start_latency_ms": 100
      },
      "hf_compat": {
        "pipeline_tag": "automatic-speech-recognition",
        "library_name": "nemo",
        "license": "apache-2.0"
      }
    },
    "parakeet-streaming-1.1b": {
      "id": "parakeet-streaming-1.1b",
      "name": "Parakeet Streaming 1.1B",
      "version": "1.0.0",
      "stage": null,
      "type": "realtime",
      "description": "Real-time streaming transcription using NVIDIA Parakeet 1.1B.\nUses cache-aware FastConformer encoder for true streaming with ~120ms latency.\nHigher accuracy variant, English-only, requires NVIDIA GPU.",
      "image": "dalston/stt-rt-parakeet-streaming-1.1b:1.0.0",
      "capabilities": {
        "stages": [],
        "languages": [
          "en"
        ],
        "supports_word_timestamps": true,
        "supports_streaming": true,
        "max_audio_duration": null,
        "max_concurrency": 4
      },
      "hardware": {
        "gpu_required": true,
        "gpu_optional": false,
        "min_vram_gb": 6,
        "recommended_gpu": [
          "a10g",
          "a100"
        ],
        "supports_cpu": false,
        "min_ram_gb": 12,
        "memory": "10G"
      },
      "performance": {
        "rtf_gpu": 0.07,
        "rtf_cpu": null,
        "warm_start_latency_ms": 120
      },
      "hf_compat": {
        "pipeline_tag": "automatic-speech-recognition",
        "library_name": "nemo",
        "license": "apache-2.0"
      }
    },
    "voxtral-streaming-mini-4b": {
      "id": "voxtral-streaming-mini-4b",
      "name": "Voxtral Streaming Mini 4B",
      "version": "1.0.0",
      "stage": null,
      "type": "realtime",
      "description": "Real-time streaming transcription using Mistral Voxtral-Mini-4B-Realtime.\nAchieves <500ms latency with configurable delay (80ms-2400ms).\nSupports 13 languages with native streaming architecture.",
      "image": "dalston/stt-rt-voxtral-streaming-mini-4b:1.0.0",
      "capabilities": {
        "stages": [],
        "languages": [
          "en",
          "zh",
          "hi",
          "es",
          "ar",
          "fr",
          "pt",
          "ru",
          "de",
          "ja",
          "ko",
          "it",
          "nl"
        ],
        "supports_word_timestamps": true,
        "supports_streaming": true,
        "max_audio_duration": null,
        "max_concurrency": 4
      },
      "hardware": {
        "gpu_required": true,
        "gpu_optional": false,
        "min_vram_gb": 16,
        "recommended_gpu": [
          "a10g",
          "l4",
          "rtx4090",
          "a100"
        ],
        "supports_cpu": false,
        "min_ram_gb": 24,
        "memory": "18G"
      },
      "performance": {
        "rtf_gpu": 0.08,
        "rtf_cpu": null,
        "warm_start_latency_ms": 200
      },
      "hf_compat": {
        "pipeline_tag": "automatic-speech-recognition",
        "library_name": "transformers",
        "license": "apache-2.0"
      }
    },
    "audio-redactor": {
      "id": "audio-redactor",
      "name": "Audio Redaction (FFmpeg)",
      "version": "1.0.0",
      "stage": "audio_redact",
      "type": null,
      "description": "Redacts audio by replacing PII segments with silence or beep tones.\nUses FFmpeg for efficient single-pass processing. Requires PII detection\noutput with entity timing information.",
      "image": "dalston/stt-batch-audio_redact-audio-redactor:1.0.0",
      "capabilities": {
        "stages": [
          "audio_redact"
        ],
        "languages": null,
        "supports_word_timestamps": false,
        "supports_streaming": false,
        "max_audio_duration": null,
        "max_concurrency": 8
      },
      "hardware": {
        "gpu_required": false,
        "gpu_optional": false,
        "min_vram_gb": 0,
        "recommended_gpu": null,
        "supports_cpu": true,
        "min_ram_gb": 2,
        "memory": "2G"
      },
      "performance": {
        "rtf_gpu": null,
        "rtf_cpu": 0.05,
        "warm_start_latency_ms": 10
      },
      "hf_compat": {
        "pipeline_tag": "dalston:audio-redaction",
        "library_name": "ffmpeg",
        "license": "apache-2.0"
      }
    },
    "faster-whisper-base": {
      "id": "faster-whisper-base",
      "name": "Faster Whisper Base",
      "version": "1.0.0",
      "stage": "transcribe",
      "type": null,
      "description": "OpenAI Whisper base model via faster-whisper (CTranslate2).\nGood balance of speed and accuracy for general transcription.\nSupports 99 languages with automatic language detection.",
      "image": "dalston/stt-batch-transcribe-faster-whisper-base:1.0.0",
      "capabilities": {
        "stages": [
          "transcribe"
        ],
        "languages": null,
        "supports_word_timestamps": false,
        "supports_streaming": false,
        "max_audio_duration": 7200,
        "max_concurrency": 4
      },
      "hardware": {
        "gpu_required": false,
        "gpu_optional": true,
        "min_vram_gb": 2,
        "recommended_gpu": [
          "t4"
        ],
        "supports_cpu": true,
        "min_ram_gb": 4,
        "memory": "4G"
      },
      "performance": {
        "rtf_gpu": 0.03,
        "rtf_cpu": 0.4,
        "warm_start_latency_ms": 30
      },
      "hf_compat": {
        "pipeline_tag": "automatic-speech-recognition",
        "library_name": "ctranslate2",
        "license": "mit",
        "source_model": "Systran/faster-whisper-base"
      },
      "input": {
        "audio_formats": [
          "wav"
        ],
        "sample_rate": 16000,
        "channels": 1
      }
    },
    "faster-whisper-large-v3-turbo": {
      "id": "faster-whisper-large-v3-turbo",
      "name": "Faster Whisper Large V3 Turbo",
      "version": "1.0.0",
      "stage": "transcribe",
      "type": null,
      "description": "OpenAI Whisper large-v3-turbo model via faster-whisper (CTranslate2).\nOptimized for speed while maintaining high accuracy.\nDistilled from large-v3 with pruned decoder for faster inference.\nSupports 99 languages with automatic language detection.",
      "image": "dalston/stt-batch-transcribe-faster-whisper-large-v3-turbo:1.0.0",
      "capabilities": {
        "stages": [
          "transcribe"
        ],
        "languages": null,
        "supports_word_timestamps": false,
        "supports_streaming": false,
        "max_audio_duration": 7200,
        "max_concurrency": 4
      },
      "hardware": {
        "gpu_required": true,
        "gpu_optional": false,
        "min_vram_gb": 4,
        "recommended_gpu": [
          "t4",
          "a10g"
        ],
        "supports_cpu": false,
        "min_ram_gb": 8,
        "memory": "6G"
      },
      "performance": {
        "rtf_gpu": 0.03,
        "rtf_cpu": null,
        "warm_start_latency_ms": 40
      },
      "hf_compat": {
        "pipeline_tag": "automatic-speech-recognition",
        "library_name": "ctranslate2",
        "license": "mit",
        "source_model": "Systran/faster-whisper-large-v3-turbo"
      },
      "input": {
        "audio_formats": [
          "wav"
        ],
        "sample_rate": 16000,
        "channels": 1
      }
    },
    "faster-whisper-large-v3": {
      "id": "faster-whisper-large-v3",
      "name": "Faster Whisper Large V3",
      "version": "1.0.0",
      "stage": "transcribe",
      "type": null,
      "description": "OpenAI Whisper large-v3 model via faster-whisper (CTranslate2).\nBest accuracy for multilingual transcription.\nSupports 99 languages with automatic language detection.",
      "image": "dalston/stt-batch-transcribe-faster-whisper-large-v3:1.0.0",
      "capabilities": {
        "stages": [
          "transcribe"
        ],
        "languages": null,
        "supports_word_timestamps": false,
        "supports_streaming": false,
        "max_audio_duration": 7200,
        "max_concurrency": 4
      },
      "hardware": {
        "gpu_required": true,
        "gpu_optional": false,
        "min_vram_gb": 6,
        "recommended_gpu": [
          "a10g",
          "a100"
        ],
        "supports_cpu": false,
        "min_ram_gb": 16,
        "memory": "8G"
      },
      "performance": {
        "rtf_gpu": 0.05,
        "rtf_cpu": null,
        "warm_start_latency_ms": 50
      },
      "hf_compat": {
        "pipeline_tag": "automatic-speech-recognition",
        "library_name": "ctranslate2",
        "license": "mit",
        "source_model": "Systran/faster-whisper-large-v3"
      },
      "input": {
        "audio_formats": [
          "wav"
        ],
        "sample_rate": 16000,
        "channels": 1
      }
    },
    "parakeet-0.6b": {
      "id": "parakeet-0.6b",
      "name": "NVIDIA Parakeet 0.6B",
      "version": "1.0.0",
      "stage": "transcribe",
      "type": null,
      "description": "NVIDIA Parakeet FastConformer RNNT 0.6B for fast English-only transcription.\nProduces native word-level timestamps without separate alignment.\nFaster variant with good accuracy, suitable for T4 GPUs.",
      "image": "dalston/stt-batch-transcribe-parakeet-0.6b:1.0.0",
      "capabilities": {
        "stages": [
          "transcribe"
        ],
        "languages": [
          "en"
        ],
        "supports_word_timestamps": true,
        "supports_streaming": false,
        "max_audio_duration": 7200,
        "max_concurrency": 4
      },
      "hardware": {
        "gpu_required": true,
        "gpu_optional": false,
        "min_vram_gb": 4,
        "recommended_gpu": [
          "t4",
          "a10g"
        ],
        "supports_cpu": false,
        "min_ram_gb": 8,
        "memory": "6G"
      },
      "performance": {
        "rtf_gpu": 0.0005,
        "rtf_cpu": null,
        "warm_start_latency_ms": 100
      },
      "hf_compat": {
        "pipeline_tag": "automatic-speech-recognition",
        "library_name": "nemo",
        "license": "apache-2.0"
      },
      "input": {
        "audio_formats": [
          "wav"
        ],
        "sample_rate": 16000,
        "channels": 1
      }
    },
    "parakeet-1.1b": {
      "id": "parakeet-1.1b",
      "name": "NVIDIA Parakeet 1.1B",
      "version": "1.0.0",
      "stage": "transcribe",
      "type": null,
      "description": "NVIDIA Parakeet FastConformer RNNT 1.1B for accurate English-only transcription.\nProduces native word-level timestamps without separate alignment.\nHigher accuracy variant, recommended for A10G or better GPUs.",
      "image": "dalston/stt-batch-transcribe-parakeet-1.1b:1.0.0",
      "capabilities": {
        "stages": [
          "transcribe"
        ],
        "languages": [
          "en"
        ],
        "supports_word_timestamps": true,
        "supports_streaming": false,
        "max_audio_duration": 7200,
        "max_concurrency": 4
      },
      "hardware": {
        "gpu_required": true,
        "gpu_optional": false,
        "min_vram_gb": 6,
        "recommended_gpu": [
          "a10g",
          "a100"
        ],
        "supports_cpu": false,
        "min_ram_gb": 12,
        "memory": "10G"
      },
      "performance": {
        "rtf_gpu": 0.0008,
        "rtf_cpu": null,
        "warm_start_latency_ms": 150
      },
      "hf_compat": {
        "pipeline_tag": "automatic-speech-recognition",
        "library_name": "nemo",
        "license": "apache-2.0"
      },
      "input": {
        "audio_formats": [
          "wav"
        ],
        "sample_rate": 16000,
        "channels": 1
      }
    },
    "voxtral-mini-3b": {
      "id": "voxtral-mini-3b",
      "name": "Mistral Voxtral Mini 3B",
      "version": "1.0.0",
      "stage": "transcribe",
      "type": null,
      "description": "Mistral Voxtral Mini 3B for multilingual transcription.\nSupports 8 languages with segment-level output.\nOptimized for edge and local deployments with ~9.5GB VRAM requirement.\nUse WhisperX align stage for word-level timestamps if needed.",
      "image": "dalston/stt-batch-transcribe-voxtral-mini-3b:1.0.0",
      "capabilities": {
        "stages": [
          "transcribe"
        ],
        "languages": [
          "en",
          "es",
          "fr",
          "pt",
          "hi",
          "de",
          "nl",
          "it"
        ],
        "supports_word_timestamps": false,
        "supports_streaming": false,
        "max_audio_duration": 1800,
        "max_concurrency": 2
      },
      "hardware": {
        "gpu_required": true,
        "gpu_optional": false,
        "min_vram_gb": 9.5,
        "recommended_gpu": [
          "a10g",
          "l4",
          "rtx4090"
        ],
        "supports_cpu": false,
        "min_ram_gb": 16,
        "memory": "12G"
      },
      "performance": {
        "rtf_gpu": 0.05,
        "rtf_cpu": null,
        "warm_start_latency_ms": 500
      },
      "hf_compat": {
        "pipeline_tag": "automatic-speech-recognition",
        "library_name": "transformers",
        "license": "apache-2.0"
      },
      "input": {
        "audio_formats": [
          "wav"
        ],
        "sample_rate": 16000,
        "channels": 1
      }
    }
  }
}
