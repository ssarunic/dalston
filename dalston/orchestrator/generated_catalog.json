{
  "generated_at": "2026-02-26T18:22:13.910386+00:00",
  "schema_version": "1.1",
  "engine_count": 20,
  "engines": {
    "phoneme-align": {
      "id": "phoneme-align",
      "name": "Phoneme Forced Alignment",
      "version": "1.0.0",
      "stage": "align",
      "type": null,
      "description": "Word-level timestamp alignment using CTC forced alignment with\nwav2vec2 models. Standalone reimplementation of the phoneme alignment\nalgorithm from the WhisperX paper (Bain et al., INTERSPEECH 2023).\n\nDoes not depend on the whisperx package. Uses torchaudio pipeline\nmodels for major European languages and HuggingFace wav2vec2 models\nfor 35+ additional languages.",
      "image": "dalston/stt-batch-align-phoneme-align:1.0.0",
      "capabilities": {
        "stages": [
          "align"
        ],
        "languages": null,
        "supports_word_timestamps": true,
        "supports_streaming": false,
        "max_audio_duration": 7200,
        "max_concurrency": 8
      },
      "hardware": {
        "gpu_required": false,
        "gpu_optional": true,
        "min_vram_gb": 2,
        "recommended_gpu": [
          "t4"
        ],
        "supports_cpu": true,
        "min_ram_gb": 4,
        "memory": "4G"
      },
      "performance": {
        "rtf_gpu": 0.02,
        "rtf_cpu": 0.3,
        "warm_start_latency_ms": 200
      },
      "input": {
        "audio_formats": [
          "wav"
        ],
        "sample_rate": 16000,
        "channels": 1
      }
    },
    "whisperx-align": {
      "id": "whisperx-align",
      "name": "WhisperX Alignment",
      "version": "1.0.0",
      "stage": "align",
      "type": null,
      "description": "Word-level timestamp alignment using WhisperX with wav2vec2-based\nforced alignment. Produces more accurate word boundaries than\ntranscription-time estimates.\n\nLoads language-specific alignment models lazily on first use.\nSupports 100+ languages via wav2vec2 models from HuggingFace.",
      "image": "dalston/stt-batch-align-whisperx-align:1.0.0",
      "capabilities": {
        "stages": [
          "align"
        ],
        "languages": null,
        "supports_word_timestamps": true,
        "supports_streaming": false,
        "max_audio_duration": 7200,
        "max_concurrency": 8
      },
      "hardware": {
        "gpu_required": false,
        "gpu_optional": true,
        "min_vram_gb": 2,
        "recommended_gpu": [
          "t4"
        ],
        "supports_cpu": true,
        "min_ram_gb": 4,
        "memory": "4G"
      },
      "performance": {
        "rtf_gpu": 0.02,
        "rtf_cpu": 0.3,
        "warm_start_latency_ms": 200
      },
      "hf_compat": {
        "pipeline_tag": "automatic-speech-recognition",
        "library_name": "whisperx",
        "license": "bsd-2-clause"
      },
      "input": {
        "audio_formats": [
          "wav"
        ],
        "sample_rate": 16000,
        "channels": 1
      }
    },
    "pii-presidio": {
      "id": "pii-presidio",
      "name": "PII Detection (Presidio + GLiNER)",
      "version": "1.0.0",
      "stage": "pii_detect",
      "type": null,
      "description": "Detects personally identifiable information using Microsoft Presidio\nwith GLiNER for ML-based entity recognition. Supports three detection\ntiers: fast (regex only), standard (+ GLiNER), thorough (+ LLM).",
      "image": "dalston/stt-batch-pii_detect-pii-presidio:1.0.0",
      "capabilities": {
        "stages": [
          "pii_detect"
        ],
        "languages": null,
        "supports_word_timestamps": false,
        "supports_streaming": false,
        "max_audio_duration": null,
        "max_concurrency": 8
      },
      "hardware": {
        "gpu_required": false,
        "gpu_optional": true,
        "min_vram_gb": 0,
        "recommended_gpu": null,
        "supports_cpu": true,
        "min_ram_gb": 4,
        "memory": "4G"
      },
      "performance": {
        "rtf_gpu": 0.01,
        "rtf_cpu": 0.05,
        "warm_start_latency_ms": 100
      },
      "hf_compat": {
        "pipeline_tag": "dalston:pii-redaction",
        "library_name": "presidio",
        "license": "mit"
      }
    },
    "nemo-msdd": {
      "id": "nemo-msdd",
      "name": "NeMo MSDD Speaker Diarization",
      "version": "1.0.0",
      "stage": "diarize",
      "type": null,
      "description": "Speaker diarization using NVIDIA NeMo Multi-scale Diarization Decoder.\nNeural end-to-end system with built-in overlap detection.\n\nNo HuggingFace token required - models are open under CC-BY-4.0 license.\nSupports optional min/max speaker count hints.\nGPU-only (CPU inference is prohibitively slow).",
      "image": "dalston/stt-batch-diarize-nemo-msdd:1.0.0",
      "capabilities": {
        "stages": [
          "diarize"
        ],
        "languages": null,
        "supports_word_timestamps": false,
        "supports_streaming": false,
        "max_audio_duration": 7200,
        "max_concurrency": 2
      },
      "hardware": {
        "gpu_required": true,
        "gpu_optional": false,
        "min_vram_gb": 4,
        "recommended_gpu": [
          "t4",
          "a10g"
        ],
        "supports_cpu": false,
        "min_ram_gb": 8,
        "memory": "8G"
      },
      "performance": {
        "rtf_gpu": 0.05,
        "rtf_cpu": null,
        "warm_start_latency_ms": 1000
      },
      "hf_compat": {
        "pipeline_tag": "speaker-diarization",
        "library_name": "nemo",
        "license": "cc-by-4.0"
      },
      "input": {
        "audio_formats": [
          "wav"
        ],
        "sample_rate": 16000,
        "channels": 1
      }
    },
    "pyannote-3.1": {
      "id": "pyannote-3.1",
      "name": "Pyannote Speaker Diarization 3.1",
      "version": "1.0.0",
      "stage": "diarize",
      "type": null,
      "description": "Speaker diarization using pyannote-audio 3.1.\nIdentifies who speaks when in an audio file.\n\nRequires HuggingFace token (HF_TOKEN) for accessing gated models.\nSupports optional min/max speaker count hints for improved accuracy.",
      "image": "dalston/stt-batch-diarize-pyannote-3.1:1.0.0",
      "capabilities": {
        "stages": [
          "diarize"
        ],
        "languages": null,
        "supports_word_timestamps": false,
        "supports_streaming": false,
        "max_audio_duration": 7200,
        "max_concurrency": 4
      },
      "hardware": {
        "gpu_required": false,
        "gpu_optional": true,
        "min_vram_gb": 2,
        "recommended_gpu": [
          "t4"
        ],
        "supports_cpu": true,
        "min_ram_gb": 6,
        "memory": "6G"
      },
      "performance": {
        "rtf_gpu": 0.1,
        "rtf_cpu": 1.5,
        "warm_start_latency_ms": 500
      },
      "hf_compat": {
        "pipeline_tag": "speaker-diarization",
        "library_name": "pyannote",
        "license": "mit"
      },
      "input": {
        "audio_formats": [
          "wav"
        ],
        "sample_rate": 16000,
        "channels": 1
      }
    },
    "pyannote-4.0": {
      "id": "pyannote-4.0",
      "name": "Pyannote Speaker Diarization 4.0",
      "version": "1.0.0",
      "stage": "diarize",
      "type": null,
      "description": "Speaker diarization using pyannote-audio 4.0 with the new Community-1 pipeline.\nIdentifies who speaks when in an audio file.\n\nNew in 4.0:\n  - VBx clustering for improved speaker counting and assignment\n  - Exclusive mode for single-speaker segments (better Whisper alignment)\n  - NumPy 2.0 and modern dependency compatibility\n\nRequires HuggingFace token (HF_TOKEN) for accessing gated models.\nSupports optional min/max speaker count hints for improved accuracy.",
      "image": "dalston/stt-batch-diarize-pyannote-4.0:1.0.0",
      "capabilities": {
        "stages": [
          "diarize"
        ],
        "languages": null,
        "supports_word_timestamps": false,
        "supports_streaming": false,
        "max_audio_duration": 7200,
        "max_concurrency": 4
      },
      "hardware": {
        "gpu_required": false,
        "gpu_optional": true,
        "min_vram_gb": 2,
        "recommended_gpu": [
          "t4"
        ],
        "supports_cpu": true,
        "min_ram_gb": 6,
        "memory": "6G"
      },
      "performance": {
        "rtf_gpu": 0.08,
        "rtf_cpu": 1.2,
        "warm_start_latency_ms": 500
      },
      "hf_compat": {
        "pipeline_tag": "speaker-diarization",
        "library_name": "pyannote",
        "license": "cc-by-4.0"
      },
      "input": {
        "audio_formats": [
          "wav"
        ],
        "sample_rate": 16000,
        "channels": 1
      }
    },
    "final-merger": {
      "id": "final-merger",
      "name": "Final Merger",
      "version": "1.1.0",
      "stage": "merge",
      "type": null,
      "description": "Combines outputs from upstream pipeline stages into the\nstandard Dalston transcript format.\n\nAdds segment IDs, metadata, and writes the canonical\ntranscript.json file for the Gateway to read.\n\nFor per_channel mode with PII detection and audio redaction:\n- Collects and merges PII entities from each channel\n- Assembles redacted mono WAVs into stereo output (FFmpeg)",
      "image": "dalston/stt-batch-merge-final-merger:1.1.0",
      "capabilities": {
        "stages": [
          "merge"
        ],
        "languages": null,
        "supports_word_timestamps": false,
        "supports_streaming": false,
        "max_audio_duration": 86400,
        "max_concurrency": 16
      },
      "hardware": {
        "gpu_required": false,
        "gpu_optional": false,
        "min_vram_gb": 0,
        "recommended_gpu": null,
        "supports_cpu": true,
        "min_ram_gb": 1,
        "memory": "256M"
      },
      "performance": {
        "rtf_gpu": null,
        "rtf_cpu": 0.001,
        "warm_start_latency_ms": 5
      },
      "hf_compat": {
        "pipeline_tag": "dalston:merge",
        "library_name": "python",
        "license": "apache-2.0"
      }
    },
    "audio-prepare": {
      "id": "audio-prepare",
      "name": "Audio Prepare",
      "version": "1.0.0",
      "stage": "prepare",
      "type": null,
      "description": "Converts any audio format to 16kHz, 16-bit, mono WAV.\nExtracts duration and audio metadata using ffprobe.\nRequired as the first stage of all batch pipelines.",
      "image": "dalston/stt-batch-prepare-audio-prepare:1.0.0",
      "capabilities": {
        "stages": [
          "prepare"
        ],
        "languages": null,
        "supports_word_timestamps": false,
        "supports_streaming": false,
        "max_audio_duration": 14400,
        "max_concurrency": 8
      },
      "hardware": {
        "gpu_required": false,
        "gpu_optional": false,
        "min_vram_gb": 0,
        "recommended_gpu": null,
        "supports_cpu": true,
        "min_ram_gb": 1,
        "memory": "512M"
      },
      "performance": {
        "rtf_gpu": null,
        "rtf_cpu": 0.1,
        "warm_start_latency_ms": 10
      },
      "hf_compat": {
        "pipeline_tag": "dalston:audio-preparation",
        "library_name": "ffmpeg",
        "license": "apache-2.0"
      },
      "input": {
        "audio_formats": [
          "mp3",
          "wav",
          "m4a",
          "flac",
          "ogg",
          "webm",
          "mp4",
          "mkv",
          "avi",
          "aac",
          "wma"
        ],
        "sample_rate": "any",
        "channels": "any"
      }
    },
    "audio-redactor": {
      "id": "audio-redactor",
      "name": "Audio Redaction (FFmpeg)",
      "version": "1.0.0",
      "stage": "audio_redact",
      "type": null,
      "description": "Redacts audio by replacing PII segments with silence or beep tones.\nUses FFmpeg for efficient single-pass processing. Requires PII detection\noutput with entity timing information.",
      "image": "dalston/stt-batch-audio_redact-audio-redactor:1.0.0",
      "capabilities": {
        "stages": [
          "audio_redact"
        ],
        "languages": null,
        "supports_word_timestamps": false,
        "supports_streaming": false,
        "max_audio_duration": null,
        "max_concurrency": 8
      },
      "hardware": {
        "gpu_required": false,
        "gpu_optional": false,
        "min_vram_gb": 0,
        "recommended_gpu": null,
        "supports_cpu": true,
        "min_ram_gb": 2,
        "memory": "2G"
      },
      "performance": {
        "rtf_gpu": null,
        "rtf_cpu": 0.05,
        "warm_start_latency_ms": 10
      },
      "hf_compat": {
        "pipeline_tag": "dalston:audio-redaction",
        "library_name": "ffmpeg",
        "license": "apache-2.0"
      }
    },
    "faster-whisper-base": {
      "id": "faster-whisper-base",
      "name": "Faster Whisper Base",
      "version": "1.0.0",
      "stage": "transcribe",
      "type": null,
      "description": "OpenAI Whisper base model via faster-whisper (CTranslate2).\nGood balance of speed and accuracy for general transcription.\nSupports 99 languages with automatic language detection.",
      "image": "dalston/stt-batch-transcribe-faster-whisper-base:1.0.0",
      "capabilities": {
        "stages": [
          "transcribe"
        ],
        "languages": null,
        "supports_word_timestamps": false,
        "supports_streaming": false,
        "max_audio_duration": 7200,
        "max_concurrency": 4
      },
      "hardware": {
        "gpu_required": false,
        "gpu_optional": true,
        "min_vram_gb": 2,
        "recommended_gpu": [
          "t4"
        ],
        "supports_cpu": true,
        "min_ram_gb": 4,
        "memory": "4G"
      },
      "performance": {
        "rtf_gpu": 0.03,
        "rtf_cpu": 0.4,
        "warm_start_latency_ms": 30
      },
      "hf_compat": {
        "pipeline_tag": "automatic-speech-recognition",
        "library_name": "ctranslate2",
        "license": "mit",
        "source_model": "Systran/faster-whisper-base"
      },
      "input": {
        "audio_formats": [
          "wav"
        ],
        "sample_rate": 16000,
        "channels": 1
      }
    },
    "parakeet-rnnt-0.6b": {
      "id": "parakeet-rnnt-0.6b",
      "name": "Parakeet RNNT 0.6B",
      "version": "1.0.0",
      "stage": null,
      "type": "realtime",
      "description": "Real-time streaming transcription using NVIDIA Parakeet RNNT 0.6B.\nUses cache-aware FastConformer encoder with RNNT decoder for true streaming.\nRNNT is the only decoder architecture that supports streaming inference.\nEnglish-only, requires NVIDIA GPU.\n\nNOTE: Outputs lowercase text without punctuation.",
      "image": "dalston/stt-rt-parakeet-rnnt-0.6b:1.0.0",
      "capabilities": {
        "stages": [],
        "languages": [
          "en"
        ],
        "supports_word_timestamps": true,
        "supports_streaming": true,
        "max_audio_duration": null,
        "max_concurrency": 4
      },
      "hardware": {
        "gpu_required": true,
        "gpu_optional": false,
        "min_vram_gb": 4,
        "recommended_gpu": [
          "t4",
          "a10g"
        ],
        "supports_cpu": false,
        "min_ram_gb": 8,
        "memory": "6G"
      },
      "performance": {
        "rtf_gpu": 0.05,
        "rtf_cpu": null,
        "warm_start_latency_ms": 100
      },
      "hf_compat": {
        "pipeline_tag": "automatic-speech-recognition",
        "library_name": "nemo",
        "license": "cc-by-4.0"
      }
    },
    "parakeet-rnnt-1.1b": {
      "id": "parakeet-rnnt-1.1b",
      "name": "Parakeet RNNT 1.1B",
      "version": "1.0.0",
      "stage": null,
      "type": "realtime",
      "description": "Real-time streaming transcription using NVIDIA Parakeet RNNT 1.1B.\nUses cache-aware FastConformer encoder with RNNT decoder for true streaming.\nHigher accuracy variant with larger model capacity.\nEnglish-only, requires NVIDIA GPU.\n\nNOTE: Outputs lowercase text without punctuation.",
      "image": "dalston/stt-rt-parakeet-rnnt-1.1b:1.0.0",
      "capabilities": {
        "stages": [],
        "languages": [
          "en"
        ],
        "supports_word_timestamps": true,
        "supports_streaming": true,
        "max_audio_duration": null,
        "max_concurrency": 4
      },
      "hardware": {
        "gpu_required": true,
        "gpu_optional": false,
        "min_vram_gb": 6,
        "recommended_gpu": [
          "a10g",
          "a100"
        ],
        "supports_cpu": false,
        "min_ram_gb": 12,
        "memory": "10G"
      },
      "performance": {
        "rtf_gpu": 0.07,
        "rtf_cpu": null,
        "warm_start_latency_ms": 120
      },
      "hf_compat": {
        "pipeline_tag": "automatic-speech-recognition",
        "library_name": "nemo",
        "license": "cc-by-4.0"
      }
    },
    "voxtral-mini-4b": {
      "id": "voxtral-mini-4b",
      "name": "Voxtral Mini 4B",
      "version": "1.0.0",
      "stage": null,
      "type": "realtime",
      "description": "Real-time streaming transcription using Mistral Voxtral-Mini-4B-Realtime.\nAchieves <500ms latency with configurable delay (80ms-2400ms).\nSupports 13 languages with native streaming architecture.",
      "image": "dalston/stt-rt-voxtral-mini-4b:1.0.0",
      "capabilities": {
        "stages": [],
        "languages": [
          "en",
          "zh",
          "hi",
          "es",
          "ar",
          "fr",
          "pt",
          "ru",
          "de",
          "ja",
          "ko",
          "it",
          "nl"
        ],
        "supports_word_timestamps": true,
        "supports_streaming": true,
        "max_audio_duration": null,
        "max_concurrency": 4
      },
      "hardware": {
        "gpu_required": true,
        "gpu_optional": false,
        "min_vram_gb": 16,
        "recommended_gpu": [
          "a10g",
          "l4",
          "rtx4090",
          "a100"
        ],
        "supports_cpu": false,
        "min_ram_gb": 24,
        "memory": "18G"
      },
      "performance": {
        "rtf_gpu": 0.08,
        "rtf_cpu": null,
        "warm_start_latency_ms": 200
      },
      "hf_compat": {
        "pipeline_tag": "automatic-speech-recognition",
        "library_name": "transformers",
        "license": "apache-2.0"
      }
    },
    "faster-whisper-large-v3-turbo": {
      "id": "faster-whisper-large-v3-turbo",
      "name": "Faster Whisper Large V3 Turbo",
      "version": "1.0.0",
      "stage": "transcribe",
      "type": null,
      "description": "OpenAI Whisper large-v3-turbo model via faster-whisper (CTranslate2).\nOptimized for speed while maintaining high accuracy.\nDistilled from large-v3 with pruned decoder for faster inference.\nSupports 99 languages with automatic language detection.",
      "image": "dalston/stt-batch-transcribe-faster-whisper-large-v3-turbo:1.0.0",
      "capabilities": {
        "stages": [
          "transcribe"
        ],
        "languages": null,
        "supports_word_timestamps": false,
        "supports_streaming": false,
        "max_audio_duration": 7200,
        "max_concurrency": 4
      },
      "hardware": {
        "gpu_required": true,
        "gpu_optional": false,
        "min_vram_gb": 4,
        "recommended_gpu": [
          "t4",
          "a10g"
        ],
        "supports_cpu": false,
        "min_ram_gb": 8,
        "memory": "6G"
      },
      "performance": {
        "rtf_gpu": 0.03,
        "rtf_cpu": null,
        "warm_start_latency_ms": 40
      },
      "hf_compat": {
        "pipeline_tag": "automatic-speech-recognition",
        "library_name": "ctranslate2",
        "license": "mit",
        "source_model": "mobiuslabsgmbh/faster-whisper-large-v3-turbo"
      },
      "input": {
        "audio_formats": [
          "wav"
        ],
        "sample_rate": 16000,
        "channels": 1
      }
    },
    "faster-whisper-large-v3": {
      "id": "faster-whisper-large-v3",
      "name": "Faster Whisper Large V3",
      "version": "1.0.0",
      "stage": "transcribe",
      "type": null,
      "description": "OpenAI Whisper large-v3 model via faster-whisper (CTranslate2).\nBest accuracy for multilingual transcription.\nSupports 99 languages with automatic language detection.",
      "image": "dalston/stt-batch-transcribe-faster-whisper-large-v3:1.0.0",
      "capabilities": {
        "stages": [
          "transcribe"
        ],
        "languages": null,
        "supports_word_timestamps": false,
        "supports_streaming": false,
        "max_audio_duration": 7200,
        "max_concurrency": 4
      },
      "hardware": {
        "gpu_required": true,
        "gpu_optional": false,
        "min_vram_gb": 6,
        "recommended_gpu": [
          "a10g",
          "a100"
        ],
        "supports_cpu": false,
        "min_ram_gb": 16,
        "memory": "8G"
      },
      "performance": {
        "rtf_gpu": 0.05,
        "rtf_cpu": null,
        "warm_start_latency_ms": 50
      },
      "hf_compat": {
        "pipeline_tag": "automatic-speech-recognition",
        "library_name": "ctranslate2",
        "license": "mit",
        "source_model": "Systran/faster-whisper-large-v3"
      },
      "input": {
        "audio_formats": [
          "wav"
        ],
        "sample_rate": 16000,
        "channels": 1
      }
    },
    "parakeet-ctc-0.6b": {
      "id": "parakeet-ctc-0.6b",
      "name": "NVIDIA Parakeet CTC 0.6B",
      "version": "1.0.0",
      "stage": "transcribe",
      "type": null,
      "description": "NVIDIA Parakeet FastConformer CTC 0.6B for fast English-only transcription.\nCTC decoder provides fastest inference with greedy decoding.\nProduces native word-level timestamps without separate alignment.\nBest choice for high-throughput batch processing.\n\nNOTE: Outputs lowercase text without punctuation. Use refine stage or\nparakeet-tdt-0.6b (v3) if punctuation/capitalization is required.",
      "image": "dalston/stt-batch-transcribe-parakeet-ctc-0.6b:1.0.0",
      "capabilities": {
        "stages": [
          "transcribe"
        ],
        "languages": [
          "en"
        ],
        "supports_word_timestamps": true,
        "supports_streaming": false,
        "max_audio_duration": 7200,
        "max_concurrency": 4
      },
      "hardware": {
        "gpu_required": true,
        "gpu_optional": false,
        "min_vram_gb": 4,
        "recommended_gpu": [
          "t4",
          "a10g"
        ],
        "supports_cpu": false,
        "min_ram_gb": 8,
        "memory": "6G"
      },
      "performance": {
        "rtf_gpu": 0.0003,
        "rtf_cpu": null,
        "warm_start_latency_ms": 100
      },
      "hf_compat": {
        "pipeline_tag": "automatic-speech-recognition",
        "library_name": "nemo",
        "license": "cc-by-4.0"
      },
      "input": {
        "audio_formats": [
          "wav"
        ],
        "sample_rate": 16000,
        "channels": 1
      }
    },
    "parakeet-ctc-1.1b": {
      "id": "parakeet-ctc-1.1b",
      "name": "NVIDIA Parakeet CTC 1.1B",
      "version": "1.0.0",
      "stage": "transcribe",
      "type": null,
      "description": "NVIDIA Parakeet FastConformer CTC 1.1B for fast English-only transcription.\nCTC decoder provides fastest inference with greedy decoding.\nLarger model with better accuracy than 0.6B variant.\nBest choice for high-throughput batch processing with quality.\n\nNOTE: Outputs lowercase text without punctuation. Use refine stage or\nparakeet-tdt-0.6b (v3) if punctuation/capitalization is required.",
      "image": "dalston/stt-batch-transcribe-parakeet-ctc-1.1b:1.0.0",
      "capabilities": {
        "stages": [
          "transcribe"
        ],
        "languages": [
          "en"
        ],
        "supports_word_timestamps": true,
        "supports_streaming": false,
        "max_audio_duration": 7200,
        "max_concurrency": 4
      },
      "hardware": {
        "gpu_required": true,
        "gpu_optional": false,
        "min_vram_gb": 6,
        "recommended_gpu": [
          "a10g",
          "a100"
        ],
        "supports_cpu": false,
        "min_ram_gb": 12,
        "memory": "10G"
      },
      "performance": {
        "rtf_gpu": 0.0005,
        "rtf_cpu": null,
        "warm_start_latency_ms": 150
      },
      "hf_compat": {
        "pipeline_tag": "automatic-speech-recognition",
        "library_name": "nemo",
        "license": "cc-by-4.0"
      },
      "input": {
        "audio_formats": [
          "wav"
        ],
        "sample_rate": 16000,
        "channels": 1
      }
    },
    "parakeet-tdt-0.6b-v3": {
      "id": "parakeet-tdt-0.6b-v3",
      "name": "NVIDIA Parakeet TDT 0.6B v3",
      "version": "1.0.0",
      "stage": "transcribe",
      "type": null,
      "description": "NVIDIA Parakeet FastConformer TDT 0.6B v3 for accurate English-only transcription.\nTDT (Token-and-Duration Transducer) provides best-in-class accuracy.\n64% faster than RNNT while achieving lower WER.\nProduces native word-level timestamps without separate alignment.\n\nNOTE: v3 includes automatic punctuation and capitalization.",
      "image": "dalston/stt-batch-transcribe-parakeet-tdt-0.6b-v3:1.0.0",
      "capabilities": {
        "stages": [
          "transcribe"
        ],
        "languages": [
          "en"
        ],
        "supports_word_timestamps": true,
        "supports_streaming": false,
        "max_audio_duration": 7200,
        "max_concurrency": 4
      },
      "hardware": {
        "gpu_required": true,
        "gpu_optional": false,
        "min_vram_gb": 4,
        "recommended_gpu": [
          "t4",
          "a10g"
        ],
        "supports_cpu": false,
        "min_ram_gb": 8,
        "memory": "6G"
      },
      "performance": {
        "rtf_gpu": 0.0004,
        "rtf_cpu": null,
        "warm_start_latency_ms": 100
      },
      "hf_compat": {
        "pipeline_tag": "automatic-speech-recognition",
        "library_name": "nemo",
        "license": "cc-by-4.0"
      },
      "input": {
        "audio_formats": [
          "wav"
        ],
        "sample_rate": 16000,
        "channels": 1
      }
    },
    "parakeet-tdt-1.1b": {
      "id": "parakeet-tdt-1.1b",
      "name": "NVIDIA Parakeet TDT 1.1B",
      "version": "1.0.0",
      "stage": "transcribe",
      "type": null,
      "description": "NVIDIA Parakeet FastConformer TDT 1.1B for highest accuracy English transcription.\nTDT (Token-and-Duration Transducer) achieves state-of-the-art WER scores.\nFirst model to achieve <7.0% average WER on HuggingFace Open ASR leaderboard.\nBest choice when transcription accuracy is the priority.\n\nNOTE: Outputs lowercase text without punctuation. Use refine stage or\nparakeet-tdt-0.6b (v3) if punctuation/capitalization is required.",
      "image": "dalston/stt-batch-transcribe-parakeet-tdt-1.1b:1.0.0",
      "capabilities": {
        "stages": [
          "transcribe"
        ],
        "languages": [
          "en"
        ],
        "supports_word_timestamps": true,
        "supports_streaming": false,
        "max_audio_duration": 7200,
        "max_concurrency": 4
      },
      "hardware": {
        "gpu_required": true,
        "gpu_optional": false,
        "min_vram_gb": 6,
        "recommended_gpu": [
          "a10g",
          "a100"
        ],
        "supports_cpu": false,
        "min_ram_gb": 12,
        "memory": "10G"
      },
      "performance": {
        "rtf_gpu": 0.0006,
        "rtf_cpu": null,
        "warm_start_latency_ms": 150
      },
      "hf_compat": {
        "pipeline_tag": "automatic-speech-recognition",
        "library_name": "nemo",
        "license": "cc-by-4.0"
      },
      "input": {
        "audio_formats": [
          "wav"
        ],
        "sample_rate": 16000,
        "channels": 1
      }
    },
    "voxtral-mini-3b": {
      "id": "voxtral-mini-3b",
      "name": "Mistral Voxtral Mini 3B",
      "version": "1.0.0",
      "stage": "transcribe",
      "type": null,
      "description": "Mistral Voxtral Mini 3B for multilingual transcription.\nSupports 8 languages with segment-level output.\nOptimized for edge and local deployments with ~9.5GB VRAM requirement.\nUse WhisperX align stage for word-level timestamps if needed.",
      "image": "dalston/stt-batch-transcribe-voxtral-mini-3b:1.0.0",
      "capabilities": {
        "stages": [
          "transcribe"
        ],
        "languages": [
          "en",
          "es",
          "fr",
          "pt",
          "hi",
          "de",
          "nl",
          "it"
        ],
        "supports_word_timestamps": false,
        "supports_streaming": false,
        "max_audio_duration": 1800,
        "max_concurrency": 2
      },
      "hardware": {
        "gpu_required": true,
        "gpu_optional": false,
        "min_vram_gb": 10,
        "recommended_gpu": [
          "a10g",
          "l4",
          "rtx4090"
        ],
        "supports_cpu": false,
        "min_ram_gb": 16,
        "memory": "12G"
      },
      "performance": {
        "rtf_gpu": 0.05,
        "rtf_cpu": null,
        "warm_start_latency_ms": 500
      },
      "hf_compat": {
        "pipeline_tag": "automatic-speech-recognition",
        "library_name": "transformers",
        "license": "apache-2.0"
      },
      "input": {
        "audio_formats": [
          "wav"
        ],
        "sample_rate": 16000,
        "channels": 1
      }
    }
  }
}
