{
  "generated_at": "2026-02-27T14:05:40.752457+00:00",
  "schema_version": "2.0",
  "runtime_count": 11,
  "model_count": 7,
  "engine_count": 11,
  "runtimes": {
    "phoneme-align": {
      "id": "phoneme-align",
      "engine_id": "phoneme-align",
      "name": "Phoneme Forced Alignment",
      "version": "1.0.0",
      "stage": "align",
      "description": "Word-level timestamp alignment using CTC forced alignment with\nwav2vec2 models. Standalone reimplementation of the phoneme alignment\nalgorithm from the WhisperX paper (Bain et al., INTERSPEECH 2023).\n\nDoes not depend on the whisperx package. Uses torchaudio pipeline\nmodels for major European languages and HuggingFace wav2vec2 models\nfor 35+ additional languages.",
      "image": "dalston/stt-batch-align-phoneme-align:1.0.0",
      "capabilities": {
        "stages": [
          "align"
        ],
        "languages": null,
        "supports_word_timestamps": true,
        "supports_streaming": false,
        "max_audio_duration": 7200,
        "max_concurrency": 8
      },
      "hardware": {
        "gpu_required": false,
        "gpu_optional": true,
        "min_vram_gb": 2,
        "recommended_gpu": [
          "t4"
        ],
        "supports_cpu": true,
        "min_ram_gb": 4,
        "memory": "4G"
      },
      "performance": {
        "rtf_gpu": 0.02,
        "rtf_cpu": 0.3,
        "warm_start_latency_ms": 200
      }
    },
    "whisperx-align": {
      "id": "whisperx-align",
      "engine_id": "whisperx-align",
      "name": "WhisperX Alignment",
      "version": "1.0.0",
      "stage": "align",
      "description": "Word-level timestamp alignment using WhisperX with wav2vec2-based\nforced alignment. Produces more accurate word boundaries than\ntranscription-time estimates.\n\nLoads language-specific alignment models lazily on first use.\nSupports 100+ languages via wav2vec2 models from HuggingFace.",
      "image": "dalston/stt-batch-align-whisperx-align:1.0.0",
      "capabilities": {
        "stages": [
          "align"
        ],
        "languages": null,
        "supports_word_timestamps": true,
        "supports_streaming": false,
        "max_audio_duration": 7200,
        "max_concurrency": 8
      },
      "hardware": {
        "gpu_required": false,
        "gpu_optional": true,
        "min_vram_gb": 2,
        "recommended_gpu": [
          "t4"
        ],
        "supports_cpu": true,
        "min_ram_gb": 4,
        "memory": "4G"
      },
      "performance": {
        "rtf_gpu": 0.02,
        "rtf_cpu": 0.3,
        "warm_start_latency_ms": 200
      }
    },
    "pii-presidio": {
      "id": "pii-presidio",
      "engine_id": "pii-presidio",
      "name": "PII Detection (GLiNER + Presidio checksum)",
      "version": "2.0.0",
      "stage": "pii_detect",
      "description": "Detects personally identifiable information using GLiNER (zero-shot NER)\nas the primary detector, supplemented by Presidio for checksum-validated\npatterns (credit cards via Luhn, IBANs via mod-97).",
      "image": "dalston/stt-batch-pii_detect-pii-presidio:2.0.0",
      "capabilities": {
        "stages": [
          "pii_detect"
        ],
        "languages": null,
        "supports_word_timestamps": false,
        "supports_streaming": false,
        "max_audio_duration": null,
        "max_concurrency": 8
      },
      "hardware": {
        "gpu_required": false,
        "gpu_optional": true,
        "min_vram_gb": 0,
        "recommended_gpu": null,
        "supports_cpu": true,
        "min_ram_gb": 4,
        "memory": "4G"
      },
      "performance": {
        "rtf_gpu": 0.01,
        "rtf_cpu": 0.05,
        "warm_start_latency_ms": 100
      }
    },
    "nemo-msdd": {
      "id": "nemo-msdd",
      "engine_id": "nemo-msdd",
      "name": "NeMo MSDD Speaker Diarization",
      "version": "1.0.0",
      "stage": "diarize",
      "description": "Speaker diarization using NVIDIA NeMo Multi-scale Diarization Decoder.\nNeural end-to-end system with built-in overlap detection.\n\nNo HuggingFace token required - models are open under CC-BY-4.0 license.\nSupports optional min/max speaker count hints.\nGPU-only (CPU inference is prohibitively slow).",
      "image": "dalston/stt-batch-diarize-nemo-msdd:1.0.0",
      "capabilities": {
        "stages": [
          "diarize"
        ],
        "languages": null,
        "supports_word_timestamps": false,
        "supports_streaming": false,
        "max_audio_duration": 7200,
        "max_concurrency": 2
      },
      "hardware": {
        "gpu_required": true,
        "gpu_optional": false,
        "min_vram_gb": 4,
        "recommended_gpu": [
          "t4",
          "a10g"
        ],
        "supports_cpu": false,
        "min_ram_gb": 8,
        "memory": "8G"
      },
      "performance": {
        "rtf_gpu": 0.05,
        "rtf_cpu": null,
        "warm_start_latency_ms": 1000
      }
    },
    "pyannote-3.1": {
      "id": "pyannote-3.1",
      "engine_id": "pyannote-3.1",
      "name": "Pyannote Speaker Diarization 3.1",
      "version": "1.0.0",
      "stage": "diarize",
      "description": "Speaker diarization using pyannote-audio 3.1.\nIdentifies who speaks when in an audio file.\n\nRequires HuggingFace token (HF_TOKEN) for accessing gated models.\nSupports optional min/max speaker count hints for improved accuracy.",
      "image": "dalston/stt-batch-diarize-pyannote-3.1:1.0.0",
      "capabilities": {
        "stages": [
          "diarize"
        ],
        "languages": null,
        "supports_word_timestamps": false,
        "supports_streaming": false,
        "max_audio_duration": 7200,
        "max_concurrency": 4
      },
      "hardware": {
        "gpu_required": false,
        "gpu_optional": true,
        "min_vram_gb": 2,
        "recommended_gpu": [
          "t4"
        ],
        "supports_cpu": true,
        "min_ram_gb": 6,
        "memory": "6G"
      },
      "performance": {
        "rtf_gpu": 0.1,
        "rtf_cpu": 1.5,
        "warm_start_latency_ms": 500
      }
    },
    "pyannote-4.0": {
      "id": "pyannote-4.0",
      "engine_id": "pyannote-4.0",
      "name": "Pyannote Speaker Diarization 4.0",
      "version": "1.0.0",
      "stage": "diarize",
      "description": "Speaker diarization using pyannote-audio 4.0 with the new Community-1 pipeline.\nIdentifies who speaks when in an audio file.\n\nNew in 4.0:\n  - VBx clustering for improved speaker counting and assignment\n  - Exclusive mode for single-speaker segments (better Whisper alignment)\n  - NumPy 2.0 and modern dependency compatibility\n\nRequires HuggingFace token (HF_TOKEN) for accessing gated models.\nSupports optional min/max speaker count hints for improved accuracy.",
      "image": "dalston/stt-batch-diarize-pyannote-4.0:1.0.0",
      "capabilities": {
        "stages": [
          "diarize"
        ],
        "languages": null,
        "supports_word_timestamps": false,
        "supports_streaming": false,
        "max_audio_duration": 7200,
        "max_concurrency": 4
      },
      "hardware": {
        "gpu_required": false,
        "gpu_optional": true,
        "min_vram_gb": 2,
        "recommended_gpu": [
          "t4"
        ],
        "supports_cpu": true,
        "min_ram_gb": 6,
        "memory": "6G"
      },
      "performance": {
        "rtf_gpu": 0.08,
        "rtf_cpu": 1.2,
        "warm_start_latency_ms": 500
      }
    },
    "final-merger": {
      "id": "final-merger",
      "engine_id": "final-merger",
      "name": "Final Merger",
      "version": "1.1.0",
      "stage": "merge",
      "description": "Combines outputs from upstream pipeline stages into the\nstandard Dalston transcript format.\n\nAdds segment IDs, metadata, and writes the canonical\ntranscript.json file for the Gateway to read.\n\nFor per_channel mode with PII detection and audio redaction:\n- Collects and merges PII entities from each channel\n- Assembles redacted mono WAVs into stereo output (FFmpeg)",
      "image": "dalston/stt-batch-merge-final-merger:1.1.0",
      "capabilities": {
        "stages": [
          "merge"
        ],
        "languages": null,
        "supports_word_timestamps": false,
        "supports_streaming": false,
        "max_audio_duration": 86400,
        "max_concurrency": 16
      },
      "hardware": {
        "gpu_required": false,
        "gpu_optional": false,
        "min_vram_gb": 0,
        "recommended_gpu": null,
        "supports_cpu": true,
        "min_ram_gb": 1,
        "memory": "256M"
      },
      "performance": {
        "rtf_gpu": null,
        "rtf_cpu": 0.001,
        "warm_start_latency_ms": 5
      }
    },
    "audio-prepare": {
      "id": "audio-prepare",
      "engine_id": "audio-prepare",
      "name": "Audio Prepare",
      "version": "1.0.0",
      "stage": "prepare",
      "description": "Converts any audio format to 16kHz, 16-bit, mono WAV.\nExtracts duration and audio metadata using ffprobe.\nRequired as the first stage of all batch pipelines.",
      "image": "dalston/stt-batch-prepare-audio-prepare:1.0.0",
      "capabilities": {
        "stages": [
          "prepare"
        ],
        "languages": null,
        "supports_word_timestamps": false,
        "supports_streaming": false,
        "max_audio_duration": 14400,
        "max_concurrency": 8
      },
      "hardware": {
        "gpu_required": false,
        "gpu_optional": false,
        "min_vram_gb": 0,
        "recommended_gpu": null,
        "supports_cpu": true,
        "min_ram_gb": 1,
        "memory": "512M"
      },
      "performance": {
        "rtf_gpu": null,
        "rtf_cpu": 0.1,
        "warm_start_latency_ms": 10
      }
    },
    "audio-redactor": {
      "id": "audio-redactor",
      "engine_id": "audio-redactor",
      "name": "Audio Redaction (FFmpeg)",
      "version": "1.0.0",
      "stage": "audio_redact",
      "description": "Redacts audio by replacing PII segments with silence or beep tones.\nUses FFmpeg for efficient single-pass processing. Requires PII detection\noutput with entity timing information.",
      "image": "dalston/stt-batch-audio_redact-audio-redactor:1.0.0",
      "capabilities": {
        "stages": [
          "audio_redact"
        ],
        "languages": null,
        "supports_word_timestamps": false,
        "supports_streaming": false,
        "max_audio_duration": null,
        "max_concurrency": 8
      },
      "hardware": {
        "gpu_required": false,
        "gpu_optional": false,
        "min_vram_gb": 0,
        "recommended_gpu": null,
        "supports_cpu": true,
        "min_ram_gb": 2,
        "memory": "2G"
      },
      "performance": {
        "rtf_gpu": null,
        "rtf_cpu": 0.05,
        "warm_start_latency_ms": 10
      }
    },
    "faster-whisper": {
      "id": "faster-whisper",
      "engine_id": "faster-whisper",
      "name": "Faster Whisper Runtime",
      "version": "1.0.0",
      "stage": "transcribe",
      "description": "Runtime engine for faster-whisper (CTranslate2-based Whisper) transcription.\nCan load any supported Whisper model variant at runtime via runtime_model_id.\n\nM36: This is a runtime-level configuration. The engine loads specific model\nvariants on demand, without requiring separate Docker images per variant.\n\nSupported models:\n  - tiny, base, small, medium (lightweight options)\n  - large-v2, large-v3 (high accuracy)\n  - large-v3-turbo (optimized balance of speed/accuracy)",
      "image": "dalston/stt-batch-transcribe-faster-whisper:1.0.0",
      "capabilities": {
        "stages": [
          "transcribe"
        ],
        "languages": null,
        "supports_word_timestamps": false,
        "supports_streaming": false,
        "max_audio_duration": 7200,
        "max_concurrency": 4
      },
      "hardware": {
        "gpu_required": false,
        "gpu_optional": true,
        "min_vram_gb": 2,
        "recommended_gpu": [
          "t4",
          "a10g"
        ],
        "supports_cpu": true,
        "min_ram_gb": 4,
        "memory": "8G"
      },
      "performance": {
        "rtf_gpu": 0.03,
        "rtf_cpu": 0.4,
        "warm_start_latency_ms": 30
      }
    },
    "nemo": {
      "id": "nemo",
      "engine_id": "nemo",
      "name": "NVIDIA NeMo Parakeet Runtime",
      "version": "1.0.0",
      "stage": "transcribe",
      "description": "Runtime engine for NVIDIA NeMo Parakeet transcription models.\nCan load any supported Parakeet model variant at runtime via runtime_model_id.\n\nM36: This is a runtime-level configuration. The engine loads specific model\nvariants on demand, without requiring separate Docker images per variant.\n\nSupported models:\n  - nvidia/parakeet-ctc-0.6b (CTC, fastest)\n  - nvidia/parakeet-ctc-1.1b (CTC, higher accuracy)\n  - nvidia/parakeet-tdt-0.6b-v3 (TDT, with punctuation)\n  - nvidia/parakeet-tdt-1.1b (TDT, highest accuracy)\n\nAll Parakeet models produce native word-level timestamps without needing\na separate alignment stage.",
      "image": "dalston/stt-batch-transcribe-nemo:1.0.0",
      "capabilities": {
        "stages": [
          "transcribe"
        ],
        "languages": [
          "en"
        ],
        "supports_word_timestamps": true,
        "supports_streaming": false,
        "max_audio_duration": 7200,
        "max_concurrency": 4
      },
      "hardware": {
        "gpu_required": true,
        "gpu_optional": false,
        "min_vram_gb": 4,
        "recommended_gpu": [
          "a10g",
          "a100"
        ],
        "supports_cpu": false,
        "min_ram_gb": 12,
        "memory": "12G"
      },
      "performance": {
        "rtf_gpu": 0.0006,
        "rtf_cpu": null,
        "warm_start_latency_ms": 150
      }
    }
  },
  "models": {
    "faster-whisper-base": {
      "id": "faster-whisper-base",
      "runtime": "faster-whisper",
      "runtime_model_id": "base",
      "name": "Faster Whisper Base",
      "source": "Systran/faster-whisper-base",
      "size_gb": 0.3,
      "stage": "transcribe",
      "description": "OpenAI Whisper base model via faster-whisper (CTranslate2).\nGood balance of speed and accuracy for general transcription.\nSupports 99 languages with automatic language detection.",
      "languages": null,
      "capabilities": {
        "word_timestamps": false,
        "punctuation": false,
        "capitalization": false,
        "streaming": false,
        "max_audio_duration": 7200
      },
      "hardware": {
        "min_vram_gb": 2,
        "supports_cpu": true,
        "min_ram_gb": 4
      },
      "performance": {
        "rtf_gpu": 0.03,
        "rtf_cpu": 0.4
      }
    },
    "faster-whisper-large-v3-turbo": {
      "id": "faster-whisper-large-v3-turbo",
      "runtime": "faster-whisper",
      "runtime_model_id": "large-v3-turbo",
      "name": "Faster Whisper Large V3 Turbo",
      "source": "Systran/faster-whisper-large-v3-turbo",
      "size_gb": 1.6,
      "stage": "transcribe",
      "description": "OpenAI Whisper large-v3-turbo model via faster-whisper (CTranslate2).\nOptimized for speed while maintaining high accuracy.\nDistilled from large-v3 with pruned decoder for faster inference.\nSupports 99 languages with automatic language detection.\nDefault model for Dalston - good balance of speed, accuracy, and compatibility.",
      "languages": null,
      "capabilities": {
        "word_timestamps": false,
        "punctuation": false,
        "capitalization": false,
        "streaming": false,
        "max_audio_duration": 7200
      },
      "hardware": {
        "min_vram_gb": 4,
        "supports_cpu": true,
        "min_ram_gb": 8
      },
      "performance": {
        "rtf_gpu": 0.03,
        "rtf_cpu": 0.3
      }
    },
    "faster-whisper-large-v3": {
      "id": "faster-whisper-large-v3",
      "runtime": "faster-whisper",
      "runtime_model_id": "large-v3",
      "name": "Faster Whisper Large V3",
      "source": "Systran/faster-whisper-large-v3",
      "size_gb": 3.0,
      "stage": "transcribe",
      "description": "OpenAI Whisper large-v3 model via faster-whisper (CTranslate2).\nBest accuracy for multilingual transcription.\nSupports 99 languages with automatic language detection.",
      "languages": null,
      "capabilities": {
        "word_timestamps": false,
        "punctuation": false,
        "capitalization": false,
        "streaming": false,
        "max_audio_duration": 7200
      },
      "hardware": {
        "min_vram_gb": 6,
        "supports_cpu": false,
        "min_ram_gb": 16
      },
      "performance": {
        "rtf_gpu": 0.05,
        "rtf_cpu": null
      }
    },
    "parakeet-ctc-0.6b": {
      "id": "parakeet-ctc-0.6b",
      "runtime": "nemo",
      "runtime_model_id": "nvidia/parakeet-ctc-0.6b",
      "name": "NVIDIA Parakeet CTC 0.6B",
      "source": "nvidia/parakeet-ctc-0.6b",
      "size_gb": 1.8,
      "stage": "transcribe",
      "description": "NVIDIA Parakeet FastConformer CTC 0.6B for fast English-only transcription.\nCTC decoder provides fastest inference with greedy decoding.\nProduces native word-level timestamps without separate alignment.\nBest choice for high-throughput batch processing.\n\nNOTE: Outputs lowercase text without punctuation. Use refine stage or\nparakeet-tdt-0.6b-v3 if punctuation/capitalization is required.",
      "languages": [
        "en"
      ],
      "capabilities": {
        "word_timestamps": true,
        "punctuation": false,
        "capitalization": false,
        "streaming": false,
        "max_audio_duration": 7200
      },
      "hardware": {
        "min_vram_gb": 4,
        "supports_cpu": false,
        "min_ram_gb": 8
      },
      "performance": {
        "rtf_gpu": 0.0003,
        "rtf_cpu": null
      }
    },
    "parakeet-ctc-1.1b": {
      "id": "parakeet-ctc-1.1b",
      "runtime": "nemo",
      "runtime_model_id": "nvidia/parakeet-ctc-1.1b",
      "name": "NVIDIA Parakeet CTC 1.1B",
      "source": "nvidia/parakeet-ctc-1.1b",
      "size_gb": 4.2,
      "stage": "transcribe",
      "description": "NVIDIA Parakeet FastConformer CTC 1.1B for fast English-only transcription.\nCTC decoder provides fastest inference with greedy decoding.\nLarger model with better accuracy than 0.6B variant.\nBest choice for high-throughput batch processing with quality.\n\nNOTE: Outputs lowercase text without punctuation. Use refine stage or\nparakeet-tdt-0.6b-v3 if punctuation/capitalization is required.",
      "languages": [
        "en"
      ],
      "capabilities": {
        "word_timestamps": true,
        "punctuation": false,
        "capitalization": false,
        "streaming": false,
        "max_audio_duration": 7200
      },
      "hardware": {
        "min_vram_gb": 6,
        "supports_cpu": false,
        "min_ram_gb": 12
      },
      "performance": {
        "rtf_gpu": 0.0005,
        "rtf_cpu": null
      }
    },
    "parakeet-tdt-0.6b-v3": {
      "id": "parakeet-tdt-0.6b-v3",
      "runtime": "nemo",
      "runtime_model_id": "nvidia/parakeet-tdt-0.6b-v3",
      "name": "NVIDIA Parakeet TDT 0.6B v3",
      "source": "nvidia/parakeet-tdt-0.6b-v3",
      "size_gb": 1.8,
      "stage": "transcribe",
      "description": "NVIDIA Parakeet FastConformer TDT 0.6B v3 for accurate English-only transcription.\nTDT (Token-and-Duration Transducer) provides best-in-class accuracy.\n64% faster than RNNT while achieving lower WER.\nProduces native word-level timestamps without separate alignment.\n\nNOTE: v3 includes automatic punctuation and capitalization.",
      "languages": [
        "en"
      ],
      "capabilities": {
        "word_timestamps": true,
        "punctuation": true,
        "capitalization": true,
        "streaming": false,
        "max_audio_duration": 7200
      },
      "hardware": {
        "min_vram_gb": 4,
        "supports_cpu": false,
        "min_ram_gb": 8
      },
      "performance": {
        "rtf_gpu": 0.0004,
        "rtf_cpu": null
      }
    },
    "parakeet-tdt-1.1b": {
      "id": "parakeet-tdt-1.1b",
      "runtime": "nemo",
      "runtime_model_id": "nvidia/parakeet-tdt-1.1b",
      "name": "NVIDIA Parakeet TDT 1.1B",
      "source": "nvidia/parakeet-tdt-1.1b",
      "size_gb": 4.2,
      "stage": "transcribe",
      "description": "NVIDIA Parakeet FastConformer TDT 1.1B for highest accuracy English transcription.\nTDT (Token-and-Duration Transducer) achieves state-of-the-art WER scores.\nFirst model to achieve <7.0% average WER on HuggingFace Open ASR leaderboard.\nBest choice when transcription accuracy is the priority.\n\nNOTE: Outputs lowercase text without punctuation. Use refine stage or\nparakeet-tdt-0.6b-v3 if punctuation/capitalization is required.",
      "languages": [
        "en"
      ],
      "capabilities": {
        "word_timestamps": true,
        "punctuation": false,
        "capitalization": false,
        "streaming": false,
        "max_audio_duration": 7200
      },
      "hardware": {
        "min_vram_gb": 6,
        "supports_cpu": false,
        "min_ram_gb": 12
      },
      "performance": {
        "rtf_gpu": 0.0006,
        "rtf_cpu": null
      }
    }
  },
  "engines": {
    "phoneme-align": {
      "id": "phoneme-align",
      "name": "Phoneme Forced Alignment",
      "version": "1.0.0",
      "stage": "align",
      "type": null,
      "description": "Word-level timestamp alignment using CTC forced alignment with\nwav2vec2 models. Standalone reimplementation of the phoneme alignment\nalgorithm from the WhisperX paper (Bain et al., INTERSPEECH 2023).\n\nDoes not depend on the whisperx package. Uses torchaudio pipeline\nmodels for major European languages and HuggingFace wav2vec2 models\nfor 35+ additional languages.",
      "image": "dalston/stt-batch-align-phoneme-align:1.0.0",
      "capabilities": {
        "stages": [
          "align"
        ],
        "languages": null,
        "supports_word_timestamps": true,
        "supports_streaming": false,
        "max_audio_duration": 7200,
        "max_concurrency": 8
      },
      "hardware": {
        "gpu_required": false,
        "gpu_optional": true,
        "min_vram_gb": 2,
        "recommended_gpu": [
          "t4"
        ],
        "supports_cpu": true,
        "min_ram_gb": 4,
        "memory": "4G"
      },
      "performance": {
        "rtf_gpu": 0.02,
        "rtf_cpu": 0.3,
        "warm_start_latency_ms": 200
      }
    },
    "whisperx-align": {
      "id": "whisperx-align",
      "name": "WhisperX Alignment",
      "version": "1.0.0",
      "stage": "align",
      "type": null,
      "description": "Word-level timestamp alignment using WhisperX with wav2vec2-based\nforced alignment. Produces more accurate word boundaries than\ntranscription-time estimates.\n\nLoads language-specific alignment models lazily on first use.\nSupports 100+ languages via wav2vec2 models from HuggingFace.",
      "image": "dalston/stt-batch-align-whisperx-align:1.0.0",
      "capabilities": {
        "stages": [
          "align"
        ],
        "languages": null,
        "supports_word_timestamps": true,
        "supports_streaming": false,
        "max_audio_duration": 7200,
        "max_concurrency": 8
      },
      "hardware": {
        "gpu_required": false,
        "gpu_optional": true,
        "min_vram_gb": 2,
        "recommended_gpu": [
          "t4"
        ],
        "supports_cpu": true,
        "min_ram_gb": 4,
        "memory": "4G"
      },
      "performance": {
        "rtf_gpu": 0.02,
        "rtf_cpu": 0.3,
        "warm_start_latency_ms": 200
      }
    },
    "pii-presidio": {
      "id": "pii-presidio",
      "name": "PII Detection (GLiNER + Presidio checksum)",
      "version": "2.0.0",
      "stage": "pii_detect",
      "type": null,
      "description": "Detects personally identifiable information using GLiNER (zero-shot NER)\nas the primary detector, supplemented by Presidio for checksum-validated\npatterns (credit cards via Luhn, IBANs via mod-97).",
      "image": "dalston/stt-batch-pii_detect-pii-presidio:2.0.0",
      "capabilities": {
        "stages": [
          "pii_detect"
        ],
        "languages": null,
        "supports_word_timestamps": false,
        "supports_streaming": false,
        "max_audio_duration": null,
        "max_concurrency": 8
      },
      "hardware": {
        "gpu_required": false,
        "gpu_optional": true,
        "min_vram_gb": 0,
        "recommended_gpu": null,
        "supports_cpu": true,
        "min_ram_gb": 4,
        "memory": "4G"
      },
      "performance": {
        "rtf_gpu": 0.01,
        "rtf_cpu": 0.05,
        "warm_start_latency_ms": 100
      }
    },
    "nemo-msdd": {
      "id": "nemo-msdd",
      "name": "NeMo MSDD Speaker Diarization",
      "version": "1.0.0",
      "stage": "diarize",
      "type": null,
      "description": "Speaker diarization using NVIDIA NeMo Multi-scale Diarization Decoder.\nNeural end-to-end system with built-in overlap detection.\n\nNo HuggingFace token required - models are open under CC-BY-4.0 license.\nSupports optional min/max speaker count hints.\nGPU-only (CPU inference is prohibitively slow).",
      "image": "dalston/stt-batch-diarize-nemo-msdd:1.0.0",
      "capabilities": {
        "stages": [
          "diarize"
        ],
        "languages": null,
        "supports_word_timestamps": false,
        "supports_streaming": false,
        "max_audio_duration": 7200,
        "max_concurrency": 2
      },
      "hardware": {
        "gpu_required": true,
        "gpu_optional": false,
        "min_vram_gb": 4,
        "recommended_gpu": [
          "t4",
          "a10g"
        ],
        "supports_cpu": false,
        "min_ram_gb": 8,
        "memory": "8G"
      },
      "performance": {
        "rtf_gpu": 0.05,
        "rtf_cpu": null,
        "warm_start_latency_ms": 1000
      }
    },
    "pyannote-3.1": {
      "id": "pyannote-3.1",
      "name": "Pyannote Speaker Diarization 3.1",
      "version": "1.0.0",
      "stage": "diarize",
      "type": null,
      "description": "Speaker diarization using pyannote-audio 3.1.\nIdentifies who speaks when in an audio file.\n\nRequires HuggingFace token (HF_TOKEN) for accessing gated models.\nSupports optional min/max speaker count hints for improved accuracy.",
      "image": "dalston/stt-batch-diarize-pyannote-3.1:1.0.0",
      "capabilities": {
        "stages": [
          "diarize"
        ],
        "languages": null,
        "supports_word_timestamps": false,
        "supports_streaming": false,
        "max_audio_duration": 7200,
        "max_concurrency": 4
      },
      "hardware": {
        "gpu_required": false,
        "gpu_optional": true,
        "min_vram_gb": 2,
        "recommended_gpu": [
          "t4"
        ],
        "supports_cpu": true,
        "min_ram_gb": 6,
        "memory": "6G"
      },
      "performance": {
        "rtf_gpu": 0.1,
        "rtf_cpu": 1.5,
        "warm_start_latency_ms": 500
      }
    },
    "pyannote-4.0": {
      "id": "pyannote-4.0",
      "name": "Pyannote Speaker Diarization 4.0",
      "version": "1.0.0",
      "stage": "diarize",
      "type": null,
      "description": "Speaker diarization using pyannote-audio 4.0 with the new Community-1 pipeline.\nIdentifies who speaks when in an audio file.\n\nNew in 4.0:\n  - VBx clustering for improved speaker counting and assignment\n  - Exclusive mode for single-speaker segments (better Whisper alignment)\n  - NumPy 2.0 and modern dependency compatibility\n\nRequires HuggingFace token (HF_TOKEN) for accessing gated models.\nSupports optional min/max speaker count hints for improved accuracy.",
      "image": "dalston/stt-batch-diarize-pyannote-4.0:1.0.0",
      "capabilities": {
        "stages": [
          "diarize"
        ],
        "languages": null,
        "supports_word_timestamps": false,
        "supports_streaming": false,
        "max_audio_duration": 7200,
        "max_concurrency": 4
      },
      "hardware": {
        "gpu_required": false,
        "gpu_optional": true,
        "min_vram_gb": 2,
        "recommended_gpu": [
          "t4"
        ],
        "supports_cpu": true,
        "min_ram_gb": 6,
        "memory": "6G"
      },
      "performance": {
        "rtf_gpu": 0.08,
        "rtf_cpu": 1.2,
        "warm_start_latency_ms": 500
      }
    },
    "final-merger": {
      "id": "final-merger",
      "name": "Final Merger",
      "version": "1.1.0",
      "stage": "merge",
      "type": null,
      "description": "Combines outputs from upstream pipeline stages into the\nstandard Dalston transcript format.\n\nAdds segment IDs, metadata, and writes the canonical\ntranscript.json file for the Gateway to read.\n\nFor per_channel mode with PII detection and audio redaction:\n- Collects and merges PII entities from each channel\n- Assembles redacted mono WAVs into stereo output (FFmpeg)",
      "image": "dalston/stt-batch-merge-final-merger:1.1.0",
      "capabilities": {
        "stages": [
          "merge"
        ],
        "languages": null,
        "supports_word_timestamps": false,
        "supports_streaming": false,
        "max_audio_duration": 86400,
        "max_concurrency": 16
      },
      "hardware": {
        "gpu_required": false,
        "gpu_optional": false,
        "min_vram_gb": 0,
        "recommended_gpu": null,
        "supports_cpu": true,
        "min_ram_gb": 1,
        "memory": "256M"
      },
      "performance": {
        "rtf_gpu": null,
        "rtf_cpu": 0.001,
        "warm_start_latency_ms": 5
      }
    },
    "audio-prepare": {
      "id": "audio-prepare",
      "name": "Audio Prepare",
      "version": "1.0.0",
      "stage": "prepare",
      "type": null,
      "description": "Converts any audio format to 16kHz, 16-bit, mono WAV.\nExtracts duration and audio metadata using ffprobe.\nRequired as the first stage of all batch pipelines.",
      "image": "dalston/stt-batch-prepare-audio-prepare:1.0.0",
      "capabilities": {
        "stages": [
          "prepare"
        ],
        "languages": null,
        "supports_word_timestamps": false,
        "supports_streaming": false,
        "max_audio_duration": 14400,
        "max_concurrency": 8
      },
      "hardware": {
        "gpu_required": false,
        "gpu_optional": false,
        "min_vram_gb": 0,
        "recommended_gpu": null,
        "supports_cpu": true,
        "min_ram_gb": 1,
        "memory": "512M"
      },
      "performance": {
        "rtf_gpu": null,
        "rtf_cpu": 0.1,
        "warm_start_latency_ms": 10
      }
    },
    "audio-redactor": {
      "id": "audio-redactor",
      "name": "Audio Redaction (FFmpeg)",
      "version": "1.0.0",
      "stage": "audio_redact",
      "type": null,
      "description": "Redacts audio by replacing PII segments with silence or beep tones.\nUses FFmpeg for efficient single-pass processing. Requires PII detection\noutput with entity timing information.",
      "image": "dalston/stt-batch-audio_redact-audio-redactor:1.0.0",
      "capabilities": {
        "stages": [
          "audio_redact"
        ],
        "languages": null,
        "supports_word_timestamps": false,
        "supports_streaming": false,
        "max_audio_duration": null,
        "max_concurrency": 8
      },
      "hardware": {
        "gpu_required": false,
        "gpu_optional": false,
        "min_vram_gb": 0,
        "recommended_gpu": null,
        "supports_cpu": true,
        "min_ram_gb": 2,
        "memory": "2G"
      },
      "performance": {
        "rtf_gpu": null,
        "rtf_cpu": 0.05,
        "warm_start_latency_ms": 10
      }
    },
    "faster-whisper": {
      "id": "faster-whisper",
      "name": "Faster Whisper Runtime",
      "version": "1.0.0",
      "stage": "transcribe",
      "type": null,
      "description": "Runtime engine for faster-whisper (CTranslate2-based Whisper) transcription.\nCan load any supported Whisper model variant at runtime via runtime_model_id.\n\nM36: This is a runtime-level configuration. The engine loads specific model\nvariants on demand, without requiring separate Docker images per variant.\n\nSupported models:\n  - tiny, base, small, medium (lightweight options)\n  - large-v2, large-v3 (high accuracy)\n  - large-v3-turbo (optimized balance of speed/accuracy)",
      "image": "dalston/stt-batch-transcribe-faster-whisper:1.0.0",
      "capabilities": {
        "stages": [
          "transcribe"
        ],
        "languages": null,
        "supports_word_timestamps": false,
        "supports_streaming": false,
        "max_audio_duration": 7200,
        "max_concurrency": 4
      },
      "hardware": {
        "gpu_required": false,
        "gpu_optional": true,
        "min_vram_gb": 2,
        "recommended_gpu": [
          "t4",
          "a10g"
        ],
        "supports_cpu": true,
        "min_ram_gb": 4,
        "memory": "8G"
      },
      "performance": {
        "rtf_gpu": 0.03,
        "rtf_cpu": 0.4,
        "warm_start_latency_ms": 30
      }
    },
    "nemo": {
      "id": "nemo",
      "name": "NVIDIA NeMo Parakeet Runtime",
      "version": "1.0.0",
      "stage": "transcribe",
      "type": null,
      "description": "Runtime engine for NVIDIA NeMo Parakeet transcription models.\nCan load any supported Parakeet model variant at runtime via runtime_model_id.\n\nM36: This is a runtime-level configuration. The engine loads specific model\nvariants on demand, without requiring separate Docker images per variant.\n\nSupported models:\n  - nvidia/parakeet-ctc-0.6b (CTC, fastest)\n  - nvidia/parakeet-ctc-1.1b (CTC, higher accuracy)\n  - nvidia/parakeet-tdt-0.6b-v3 (TDT, with punctuation)\n  - nvidia/parakeet-tdt-1.1b (TDT, highest accuracy)\n\nAll Parakeet models produce native word-level timestamps without needing\na separate alignment stage.",
      "image": "dalston/stt-batch-transcribe-nemo:1.0.0",
      "capabilities": {
        "stages": [
          "transcribe"
        ],
        "languages": [
          "en"
        ],
        "supports_word_timestamps": true,
        "supports_streaming": false,
        "max_audio_duration": 7200,
        "max_concurrency": 4
      },
      "hardware": {
        "gpu_required": true,
        "gpu_optional": false,
        "min_vram_gb": 4,
        "recommended_gpu": [
          "a10g",
          "a100"
        ],
        "supports_cpu": false,
        "min_ram_gb": 12,
        "memory": "12G"
      },
      "performance": {
        "rtf_gpu": 0.0006,
        "rtf_cpu": null,
        "warm_start_latency_ms": 150
      }
    }
  }
}
