schema_version: "1.1"
id: pyannote-4.0
runtime: pyannote-4.0
stage: diarize
name: Pyannote Speaker Diarization 4.0
version: 1.0.0
description: |
  Speaker diarization using pyannote-audio 4.0 with the new Community-1 pipeline.
  Identifies who speaks when in an audio file.

  New in 4.0:
    - VBx clustering for improved speaker counting and assignment
    - Exclusive mode for single-speaker segments (better Whisper alignment)
    - NumPy 2.0 and modern dependency compatibility

  Requires HuggingFace token (HF_TOKEN) for accessing gated models.
  Supports optional min/max speaker count hints for improved accuracy.

container:
  gpu: optional  # Recommended for performance; very slow on CPU
  memory: 6G
  model_cache: /models

capabilities:
  languages:
    - all  # Language-agnostic speaker diarization
  max_audio_duration: 7200  # 2 hours
  streaming: false
  max_concurrency: 4

input:
  audio_formats:
    - wav
  sample_rate: 16000
  channels: 1

config_schema:
  type: object
  properties:
    min_speakers:
      type: integer
      minimum: 1
      description: Minimum number of speakers (hint for clustering)
    max_speakers:
      type: integer
      minimum: 1
      description: Maximum number of speakers (hint for clustering)
    exclusive:
      type: boolean
      default: false
      description: |
        Enable exclusive diarization mode (new in 4.0).
        When enabled, each segment has exactly one speaker assigned,
        making it easier to align with Whisper transcription timestamps.
  additionalProperties: false

output_schema:
  type: object
  required:
    - speakers
    - turns
    - num_speakers
  properties:
    speakers:
      type: array
      description: List of detected speaker IDs
      items:
        type: string
    turns:
      type: array
      description: Speaker turns with timestamps
      items:
        type: object
        required:
          - start
          - end
          - speaker
        properties:
          start:
            type: number
            description: Segment start time in seconds
          end:
            type: number
            description: Segment end time in seconds
          speaker:
            type: string
            description: Speaker ID (e.g., "SPEAKER_00")
    num_speakers:
      type: integer
      description: Number of speakers detected
    overlap_duration:
      type: number
      description: Total duration of overlapping speech in seconds
    overlap_ratio:
      type: number
      description: Fraction of audio with overlapping speech
    exclusive_mode:
      type: boolean
      description: Whether exclusive diarization mode was used
    engine_id:
      type: string
      description: Engine identifier
    skipped:
      type: boolean
      description: Whether processing was skipped
    skip_reason:
      type: string
      description: Reason for skipping if skipped
    warnings:
      type: array
      items:
        type: string
      description: Any processing warnings

hf_compat:
  pipeline_tag: speaker-diarization
  library_name: pyannote
  license: cc-by-4.0

hardware:
  min_vram_gb: 2
  recommended_gpu:
    - t4
  supports_cpu: true
  min_ram_gb: 6

performance:
  rtf_gpu: 0.08
  rtf_cpu: 1.2
  warm_start_latency_ms: 500
