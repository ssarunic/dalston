schema_version: "1.1"
id: faster-whisper-base
type: realtime
name: Faster Whisper Base
version: 1.0.0
description: |
  Real-time streaming transcription using faster-whisper (CTranslate2).
  Supports both "fast" (distil-whisper) and "accurate" (large-v3) model modes.
  Uses Silero VAD for speech boundary detection.

container:
  gpu: optional
  memory: 12G
  model_cache: /models

capabilities:
  languages:
    - all
  max_concurrency: 4
  streaming: true
  word_timestamps: true

server:
  port: 9000
  protocol: websocket
  path: /session

models:
  fast:
    name: distil-whisper/distil-large-v3
    description: Distil-Whisper for low-latency transcription
    latency: low
    accuracy: good
  accurate:
    name: large-v3
    description: Whisper large-v3 for high accuracy
    latency: medium
    accuracy: excellent

audio:
  encodings:
    - pcm_s16le
    - pcm_f32le
    - mulaw
    - alaw
  sample_rates:
    - 16000
  channels: 1

vad:
  engine: silero
  threshold: 0.5
  min_speech_duration_ms: 250
  min_silence_duration_ms: 500
  lookback_ms: 300

heartbeat:
  interval_seconds: 10
  timeout_seconds: 30

environment:
  WORKER_ID:
    description: Unique identifier for this worker
    required: true
  WORKER_PORT:
    description: WebSocket server port
    default: "9000"
  MAX_SESSIONS:
    description: Maximum concurrent sessions
    default: "4"
  REDIS_URL:
    description: Redis connection URL
    default: redis://localhost:6379
  FAST_MODEL:
    description: Model for "fast" variant
    default: distil-whisper/distil-large-v3
  ACCURATE_MODEL:
    description: Model for "accurate" variant
    default: large-v3

hf_compat:
  pipeline_tag: automatic-speech-recognition
  library_name: ctranslate2
  license: mit

hardware:
  min_vram_gb: 6
  recommended_gpu:
    - t4
    - a10g
  supports_cpu: true
  min_ram_gb: 12

performance:
  rtf_gpu: 0.1
  rtf_cpu: 0.5
  warm_start_latency_ms: 200
