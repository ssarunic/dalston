# Dalston - Modular Audio Transcription Server
#
# Container Naming Convention:
#   {type}-{domain}-{stage}-{impl}[-v{version}][-cpu]
#   - type: batch (file processing) or rt (realtime streaming)
#   - domain: stt (speech-to-text), tts (text-to-speech, future)
#   - stage: prepare, transcribe, align, diarize, pii_detect, audio_redact, refine, merge
#   - impl: whisper, parakeet, pyannote, presidio, etc.
#   - version: v31, v40, etc. (only when multiple versions coexist)
#   - cpu: only when forcing CPU mode (GPU is default for compute-heavy engines)
#
# Image Sharing Strategy:
#   Services that use the same Dockerfile share a single image via the `image:` directive.
#   Only the first service has a `build:` section; others just reference the image.
#   This saves disk space and ensures consistency.
#
# Usage:
#   docker compose up -d
#   docker compose up -d --scale stt-batch-transcribe-whisper=2  # scale specific engine

services:
  # ============================================================
  # INFRASTRUCTURE
  # ============================================================

  postgres:
    image: postgres:16-alpine
    environment:
      POSTGRES_USER: dalston
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD:-password}
      POSTGRES_DB: dalston
    ports:
      - "5432:5432"
    volumes:
      - postgres-data:/var/lib/postgresql/data
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U dalston"]
      interval: 5s
      timeout: 5s
      retries: 5
    restart: unless-stopped

  redis:
    image: redis:7-alpine
    command: redis-server --appendonly no
    ports:
      - "6379:6379"
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 5s
      timeout: 5s
      retries: 5
    restart: unless-stopped

  minio:
    image: minio/minio:latest
    command: server /data --console-address ":9001"
    environment:
      MINIO_ROOT_USER: ${MINIO_ROOT_USER:-minioadmin}
      MINIO_ROOT_PASSWORD: ${MINIO_ROOT_PASSWORD:-minioadmin}
    ports:
      - "9000:9000"
      - "9001:9001"
    volumes:
      - minio-data:/data
    healthcheck:
      test: ["CMD", "mc", "ready", "local"]
      interval: 5s
      timeout: 5s
      retries: 5
    restart: unless-stopped

  # Initialize MinIO bucket before gateway starts
  minio-init:
    image: minio/mc:latest
    depends_on:
      minio:
        condition: service_healthy
    entrypoint: >
      /bin/sh -c "
      mc alias set dalston http://minio:9000 $${MINIO_ROOT_USER:-minioadmin} $${MINIO_ROOT_PASSWORD:-minioadmin};
      mc mb dalston/$${S3_BUCKET:-dalston-artifacts} --ignore-existing;
      exit 0;
      "
    environment:
      MINIO_ROOT_USER: ${MINIO_ROOT_USER:-minioadmin}
      MINIO_ROOT_PASSWORD: ${MINIO_ROOT_PASSWORD:-minioadmin}
      S3_BUCKET: ${S3_BUCKET:-dalston-artifacts}

  # Jaeger for distributed tracing (M19)
  # Enable with: docker compose --profile tracing up -d
  # UI available at: http://localhost:16686
  jaeger:
    image: jaegertracing/all-in-one:1.54
    ports:
      - "16686:16686"  # Jaeger UI
      - "4317:4317"    # OTLP gRPC receiver
      - "4318:4318"    # OTLP HTTP receiver
    environment:
      - COLLECTOR_OTLP_ENABLED=true
    profiles:
      - tracing
    restart: unless-stopped

  # Prometheus for metrics collection (M20)
  # Enable with: docker compose --profile monitoring up -d
  # UI available at: http://localhost:9090
  prometheus:
    image: prom/prometheus:v2.50.0
    volumes:
      - ./docker/prometheus/prometheus.yml:/etc/prometheus/prometheus.yml:ro
      - prometheus-data:/prometheus
    ports:
      - "9090:9090"
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--web.enable-lifecycle'
      - '--storage.tsdb.retention.time=1d'
      - '--storage.tsdb.retention.size=500MB'
    profiles:
      - monitoring
    restart: unless-stopped

  # Grafana for dashboards (M20)
  # Enable with: docker compose --profile monitoring up -d
  # UI available at: http://localhost:3001 (admin/dalston)
  grafana:
    image: grafana/grafana:10.3.0
    volumes:
      - ./docker/grafana/provisioning:/etc/grafana/provisioning:ro
      - ./docker/grafana/dashboards:/var/lib/grafana/dashboards:ro
      - grafana-data:/var/lib/grafana
    ports:
      - "3001:3000"
    environment:
      - GF_SECURITY_ADMIN_PASSWORD=dalston
      - GF_AUTH_ANONYMOUS_ENABLED=true
      - GF_AUTH_ANONYMOUS_ORG_ROLE=Viewer
      - GF_DASHBOARDS_DEFAULT_HOME_DASHBOARD_PATH=/var/lib/grafana/dashboards/dalston-overview.json
    depends_on:
      - prometheus
    profiles:
      - monitoring
    restart: unless-stopped

  # Metrics exporter for Redis queue depths (M20)
  # Enable with: docker compose --profile monitoring up -d
  metrics-exporter:
    image: dalston/gateway:latest
    command: python -m dalston.metrics_exporter
    environment:
      - REDIS_URL=redis://redis:6379
      - METRICS_PORT=9100
      - SCRAPE_INTERVAL=15
      - LOG_LEVEL=${LOG_LEVEL:-INFO}
      - LOG_FORMAT=${LOG_FORMAT:-json}
    depends_on:
      redis:
        condition: service_healthy
    profiles:
      - monitoring
    restart: unless-stopped

  # ============================================================
  # CORE SERVICES
  # ============================================================

  gateway:
    image: dalston/gateway:latest
    build:
      context: .
      dockerfile: docker/Dockerfile.gateway
    ports:
      - "8000:8000"
    profiles:
      - prod
    environment:
      - DATABASE_URL=postgresql+asyncpg://dalston:${POSTGRES_PASSWORD:-password}@postgres:5432/dalston
      - REDIS_URL=redis://redis:6379
      - S3_BUCKET=${S3_BUCKET:-dalston-artifacts}
      - S3_REGION=${S3_REGION:-us-east-1}
      - S3_ENDPOINT_URL=http://minio:9000
      - AWS_ACCESS_KEY_ID=${MINIO_ROOT_USER:-minioadmin}
      - AWS_SECRET_ACCESS_KEY=${MINIO_ROOT_PASSWORD:-minioadmin}
      - LOG_LEVEL=${LOG_LEVEL:-INFO}
      - LOG_FORMAT=${LOG_FORMAT:-json}
      # Distributed tracing (M19) - enable with OTEL_ENABLED=true
      - OTEL_ENABLED=${OTEL_ENABLED:-false}
      - OTEL_EXPORTER_OTLP_ENDPOINT=${OTEL_EXPORTER_OTLP_ENDPOINT:-http://jaeger:4317}
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
      minio-init:
        condition: service_completed_successfully
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 10s
      timeout: 5s
      retries: 5
    restart: unless-stopped

  orchestrator:
    image: dalston/orchestrator:latest
    build:
      context: .
      dockerfile: docker/Dockerfile.orchestrator
    profiles:
      - prod
    environment:
      - DATABASE_URL=postgresql+asyncpg://dalston:${POSTGRES_PASSWORD:-password}@postgres:5432/dalston
      - REDIS_URL=redis://redis:6379
      - S3_BUCKET=${S3_BUCKET:-dalston-artifacts}
      - S3_REGION=${S3_REGION:-us-east-1}
      - S3_ENDPOINT_URL=http://minio:9000
      - AWS_ACCESS_KEY_ID=${MINIO_ROOT_USER:-minioadmin}
      - AWS_SECRET_ACCESS_KEY=${MINIO_ROOT_PASSWORD:-minioadmin}
      - LOG_LEVEL=${LOG_LEVEL:-INFO}
      - LOG_FORMAT=${LOG_FORMAT:-json}
      # Distributed tracing (M19) - enable with OTEL_ENABLED=true
      - OTEL_ENABLED=${OTEL_ENABLED:-false}
      - OTEL_EXPORTER_OTLP_ENDPOINT=${OTEL_EXPORTER_OTLP_ENDPOINT:-http://jaeger:4317}
      # Prometheus metrics (M20) - enabled by default
      - METRICS_ENABLED=${METRICS_ENABLED:-true}
      - METRICS_PORT=8001
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
    restart: unless-stopped

  # ============================================================
  # BATCH STT ENGINES
  # ============================================================

  # --- PREPARE STAGE ---
  stt-batch-prepare:
    image: dalston/stt-batch-prepare:latest
    build:
      context: .
      dockerfile: engines/prepare/audio-prepare/Dockerfile
    environment:
      - ENGINE_ID=audio-prepare
      - REDIS_URL=redis://redis:6379
      - S3_BUCKET=${S3_BUCKET:-dalston-artifacts}
      - S3_REGION=${S3_REGION:-us-east-1}
      - S3_ENDPOINT_URL=http://minio:9000
      - AWS_ACCESS_KEY_ID=${MINIO_ROOT_USER:-minioadmin}
      - AWS_SECRET_ACCESS_KEY=${MINIO_ROOT_PASSWORD:-minioadmin}
      - LOG_LEVEL=${LOG_LEVEL:-INFO}
      - LOG_FORMAT=${LOG_FORMAT:-json}
      - OTEL_ENABLED=${OTEL_ENABLED:-false}
      - OTEL_EXPORTER_OTLP_ENDPOINT=${OTEL_EXPORTER_OTLP_ENDPOINT:-http://jaeger:4317}
      # Prometheus metrics (M20)
      - METRICS_ENABLED=${METRICS_ENABLED:-true}
      - METRICS_PORT=9100
    depends_on:
      redis:
        condition: service_healthy
      minio-init:
        condition: service_completed_successfully
    restart: unless-stopped

  # --- TRANSCRIBE STAGE ---
  # NVIDIA Parakeet transcription (CPU - default for local dev)
  stt-batch-transcribe-parakeet-cpu:
    image: dalston/stt-batch-transcribe-parakeet:cpu
    build:
      context: .
      dockerfile: engines/transcribe/parakeet/Dockerfile
      args:
        DEVICE: cpu
    environment:
      - ENGINE_ID=parakeet
      - REDIS_URL=redis://redis:6379
      - S3_BUCKET=${S3_BUCKET:-dalston-artifacts}
      - S3_REGION=${S3_REGION:-us-east-1}
      - S3_ENDPOINT_URL=http://minio:9000
      - AWS_ACCESS_KEY_ID=${MINIO_ROOT_USER:-minioadmin}
      - AWS_SECRET_ACCESS_KEY=${MINIO_ROOT_PASSWORD:-minioadmin}
      - LOG_LEVEL=${LOG_LEVEL:-INFO}
      - LOG_FORMAT=${LOG_FORMAT:-json}
      # Prometheus metrics (M20)
      - METRICS_ENABLED=${METRICS_ENABLED:-true}
      - METRICS_PORT=9100
    volumes:
      - parakeet-models:/models
    depends_on:
      redis:
        condition: service_healthy
      minio-init:
        condition: service_completed_successfully
    restart: unless-stopped

  # NVIDIA Parakeet transcription (GPU - use with: docker compose --profile gpu up -d)
  stt-batch-transcribe-parakeet:
    image: dalston/stt-batch-transcribe-parakeet:latest
    build:
      context: .
      dockerfile: engines/transcribe/parakeet/Dockerfile
    environment:
      - ENGINE_ID=parakeet
      - REDIS_URL=redis://redis:6379
      - S3_BUCKET=${S3_BUCKET:-dalston-artifacts}
      - S3_REGION=${S3_REGION:-us-east-1}
      - S3_ENDPOINT_URL=http://minio:9000
      - AWS_ACCESS_KEY_ID=${MINIO_ROOT_USER:-minioadmin}
      - AWS_SECRET_ACCESS_KEY=${MINIO_ROOT_PASSWORD:-minioadmin}
      - LOG_LEVEL=${LOG_LEVEL:-INFO}
      - LOG_FORMAT=${LOG_FORMAT:-json}
      # Prometheus metrics (M20)
      - METRICS_ENABLED=${METRICS_ENABLED:-true}
      - METRICS_PORT=9100
    volumes:
      - parakeet-models:/models
    depends_on:
      redis:
        condition: service_healthy
      minio-init:
        condition: service_completed_successfully
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
    profiles:
      - gpu
    restart: unless-stopped

  # Faster-Whisper transcription (CPU - use with: docker compose --profile whisper up -d)
  stt-batch-transcribe-whisper-cpu:
    image: dalston/stt-batch-transcribe-whisper:latest
    build:
      context: .
      dockerfile: engines/transcribe/faster-whisper/Dockerfile
    environment:
      - ENGINE_ID=faster-whisper
      - REDIS_URL=redis://redis:6379
      - S3_BUCKET=${S3_BUCKET:-dalston-artifacts}
      - S3_REGION=${S3_REGION:-us-east-1}
      - S3_ENDPOINT_URL=http://minio:9000
      - AWS_ACCESS_KEY_ID=${MINIO_ROOT_USER:-minioadmin}
      - AWS_SECRET_ACCESS_KEY=${MINIO_ROOT_PASSWORD:-minioadmin}
      - LOG_LEVEL=${LOG_LEVEL:-INFO}
      - LOG_FORMAT=${LOG_FORMAT:-json}
      - OTEL_ENABLED=${OTEL_ENABLED:-false}
      - OTEL_EXPORTER_OTLP_ENDPOINT=${OTEL_EXPORTER_OTLP_ENDPOINT:-http://jaeger:4317}
      # Prometheus metrics (M20)
      - METRICS_ENABLED=${METRICS_ENABLED:-true}
      - METRICS_PORT=9100
    volumes:
      - whisper-models:/models
    depends_on:
      redis:
        condition: service_healthy
      minio-init:
        condition: service_completed_successfully
    profiles:
      - whisper
    restart: unless-stopped

  # Faster-Whisper transcription (GPU - use with: docker compose --profile gpu up -d)
  stt-batch-transcribe-whisper:
    image: dalston/stt-batch-transcribe-whisper:latest
    environment:
      - ENGINE_ID=faster-whisper
      - REDIS_URL=redis://redis:6379
      - S3_BUCKET=${S3_BUCKET:-dalston-artifacts}
      - S3_REGION=${S3_REGION:-us-east-1}
      - S3_ENDPOINT_URL=http://minio:9000
      - AWS_ACCESS_KEY_ID=${MINIO_ROOT_USER:-minioadmin}
      - AWS_SECRET_ACCESS_KEY=${MINIO_ROOT_PASSWORD:-minioadmin}
      - LOG_LEVEL=${LOG_LEVEL:-INFO}
      - LOG_FORMAT=${LOG_FORMAT:-json}
    volumes:
      - whisper-models:/models
    depends_on:
      redis:
        condition: service_healthy
      minio-init:
        condition: service_completed_successfully
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
    profiles:
      - gpu
    restart: unless-stopped

  # --- ALIGN STAGE ---
  # WhisperX alignment (CPU - default for local dev)
  stt-batch-align-whisperx-cpu:
    image: dalston/stt-batch-align-whisperx:latest
    build:
      context: .
      dockerfile: engines/align/whisperx-align/Dockerfile
    environment:
      - ENGINE_ID=whisperx-align
      - REDIS_URL=redis://redis:6379
      - S3_BUCKET=${S3_BUCKET:-dalston-artifacts}
      - S3_REGION=${S3_REGION:-us-east-1}
      - S3_ENDPOINT_URL=http://minio:9000
      - AWS_ACCESS_KEY_ID=${MINIO_ROOT_USER:-minioadmin}
      - AWS_SECRET_ACCESS_KEY=${MINIO_ROOT_PASSWORD:-minioadmin}
      - LOG_LEVEL=${LOG_LEVEL:-INFO}
      - LOG_FORMAT=${LOG_FORMAT:-json}
      - OTEL_ENABLED=${OTEL_ENABLED:-false}
      - OTEL_EXPORTER_OTLP_ENDPOINT=${OTEL_EXPORTER_OTLP_ENDPOINT:-http://jaeger:4317}
      # Prometheus metrics (M20)
      - METRICS_ENABLED=${METRICS_ENABLED:-true}
      - METRICS_PORT=9100
    volumes:
      - align-models:/models
    depends_on:
      redis:
        condition: service_healthy
      minio-init:
        condition: service_completed_successfully
    restart: unless-stopped

  # WhisperX alignment (GPU - use with: docker compose --profile gpu up -d)
  stt-batch-align-whisperx:
    image: dalston/stt-batch-align-whisperx:latest
    environment:
      - ENGINE_ID=whisperx-align
      - REDIS_URL=redis://redis:6379
      - S3_BUCKET=${S3_BUCKET:-dalston-artifacts}
      - S3_REGION=${S3_REGION:-us-east-1}
      - S3_ENDPOINT_URL=http://minio:9000
      - AWS_ACCESS_KEY_ID=${MINIO_ROOT_USER:-minioadmin}
      - AWS_SECRET_ACCESS_KEY=${MINIO_ROOT_PASSWORD:-minioadmin}
      - LOG_LEVEL=${LOG_LEVEL:-INFO}
      - LOG_FORMAT=${LOG_FORMAT:-json}
      - OTEL_ENABLED=${OTEL_ENABLED:-false}
      - OTEL_EXPORTER_OTLP_ENDPOINT=${OTEL_EXPORTER_OTLP_ENDPOINT:-http://jaeger:4317}
    volumes:
      - align-models:/models
    depends_on:
      redis:
        condition: service_healthy
      minio-init:
        condition: service_completed_successfully
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
    profiles:
      - gpu
    restart: unless-stopped

  # --- DIARIZE STAGE ---
  # Pyannote 3.1 diarization (CPU - default for local dev)
  stt-batch-diarize-pyannote-v31-cpu:
    image: dalston/stt-batch-diarize-pyannote-v31:latest
    build:
      context: .
      dockerfile: engines/diarize/pyannote-3.1/Dockerfile
    environment:
      - ENGINE_ID=pyannote-3.1
      - REDIS_URL=redis://redis:6379
      - S3_BUCKET=${S3_BUCKET:-dalston-artifacts}
      - S3_REGION=${S3_REGION:-us-east-1}
      - S3_ENDPOINT_URL=http://minio:9000
      - AWS_ACCESS_KEY_ID=${MINIO_ROOT_USER:-minioadmin}
      - AWS_SECRET_ACCESS_KEY=${MINIO_ROOT_PASSWORD:-minioadmin}
      - HF_TOKEN=${HF_TOKEN:-}
      - DIARIZATION_DISABLED=${DIARIZATION_DISABLED:-false}
      - LOG_LEVEL=${LOG_LEVEL:-INFO}
      - LOG_FORMAT=${LOG_FORMAT:-json}
      # Prometheus metrics (M20)
      - METRICS_ENABLED=${METRICS_ENABLED:-true}
      - METRICS_PORT=9100
    volumes:
      - pyannote-models:/models
    depends_on:
      redis:
        condition: service_healthy
      minio-init:
        condition: service_completed_successfully
    restart: unless-stopped

  # Pyannote 3.1 diarization (GPU - use with: docker compose --profile gpu up -d)
  stt-batch-diarize-pyannote-v31:
    image: dalston/stt-batch-diarize-pyannote-v31:latest
    environment:
      - ENGINE_ID=pyannote-3.1
      - REDIS_URL=redis://redis:6379
      - S3_BUCKET=${S3_BUCKET:-dalston-artifacts}
      - S3_REGION=${S3_REGION:-us-east-1}
      - S3_ENDPOINT_URL=http://minio:9000
      - AWS_ACCESS_KEY_ID=${MINIO_ROOT_USER:-minioadmin}
      - AWS_SECRET_ACCESS_KEY=${MINIO_ROOT_PASSWORD:-minioadmin}
      - HF_TOKEN=${HF_TOKEN:-}
      - LOG_LEVEL=${LOG_LEVEL:-INFO}
      - LOG_FORMAT=${LOG_FORMAT:-json}
    volumes:
      - pyannote-models:/models
    depends_on:
      redis:
        condition: service_healthy
      minio-init:
        condition: service_completed_successfully
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
    profiles:
      - gpu
    restart: unless-stopped

  # Pyannote 4.0 diarization (CPU - default for local dev)
  stt-batch-diarize-pyannote-v40-cpu:
    image: dalston/stt-batch-diarize-pyannote-v40:latest
    build:
      context: .
      dockerfile: engines/diarize/pyannote-4.0/Dockerfile
    environment:
      - ENGINE_ID=pyannote-4.0
      - REDIS_URL=redis://redis:6379
      - S3_BUCKET=${S3_BUCKET:-dalston-artifacts}
      - S3_REGION=${S3_REGION:-us-east-1}
      - S3_ENDPOINT_URL=http://minio:9000
      - AWS_ACCESS_KEY_ID=${MINIO_ROOT_USER:-minioadmin}
      - AWS_SECRET_ACCESS_KEY=${MINIO_ROOT_PASSWORD:-minioadmin}
      - HF_TOKEN=${HF_TOKEN:-}
      - DIARIZATION_DISABLED=${DIARIZATION_DISABLED:-false}
      - LOG_LEVEL=${LOG_LEVEL:-INFO}
      - LOG_FORMAT=${LOG_FORMAT:-json}
      # Prometheus metrics (M20)
      - METRICS_ENABLED=${METRICS_ENABLED:-true}
      - METRICS_PORT=9100
    volumes:
      - pyannote-models:/models
    depends_on:
      redis:
        condition: service_healthy
      minio-init:
        condition: service_completed_successfully
    restart: unless-stopped

  # Pyannote 4.0 diarization (GPU - use with: docker compose --profile gpu up -d)
  stt-batch-diarize-pyannote-v40:
    image: dalston/stt-batch-diarize-pyannote-v40:latest
    environment:
      - ENGINE_ID=pyannote-4.0
      - REDIS_URL=redis://redis:6379
      - S3_BUCKET=${S3_BUCKET:-dalston-artifacts}
      - S3_REGION=${S3_REGION:-us-east-1}
      - S3_ENDPOINT_URL=http://minio:9000
      - AWS_ACCESS_KEY_ID=${MINIO_ROOT_USER:-minioadmin}
      - AWS_SECRET_ACCESS_KEY=${MINIO_ROOT_PASSWORD:-minioadmin}
      - HF_TOKEN=${HF_TOKEN:-}
      - LOG_LEVEL=${LOG_LEVEL:-INFO}
      - LOG_FORMAT=${LOG_FORMAT:-json}
    volumes:
      - pyannote-models:/models
    depends_on:
      redis:
        condition: service_healthy
      minio-init:
        condition: service_completed_successfully
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
    profiles:
      - gpu
    restart: unless-stopped

  # --- DETECT STAGE (PII) ---
  stt-batch-detect-presidio:
    image: dalston/stt-batch-detect-presidio:latest
    build:
      context: .
      dockerfile: engines/detect/pii-presidio/Dockerfile
    environment:
      - ENGINE_ID=pii-presidio
      - REDIS_URL=redis://redis:6379
      - S3_BUCKET=${S3_BUCKET:-dalston-artifacts}
      - S3_REGION=${S3_REGION:-us-east-1}
      - S3_ENDPOINT_URL=http://minio:9000
      - AWS_ACCESS_KEY_ID=${MINIO_ROOT_USER:-minioadmin}
      - AWS_SECRET_ACCESS_KEY=${MINIO_ROOT_PASSWORD:-minioadmin}
      - LOG_LEVEL=${LOG_LEVEL:-INFO}
      - LOG_FORMAT=${LOG_FORMAT:-json}
      # Prometheus metrics (M20)
      - METRICS_ENABLED=${METRICS_ENABLED:-true}
      - METRICS_PORT=9100
    volumes:
      - gliner-models:/models
    depends_on:
      redis:
        condition: service_healthy
      minio-init:
        condition: service_completed_successfully
    restart: unless-stopped

  # --- REDACT STAGE ---
  stt-batch-redact-audio:
    image: dalston/stt-batch-redact-audio:latest
    build:
      context: .
      dockerfile: engines/redact/audio-redactor/Dockerfile
    environment:
      - ENGINE_ID=audio-redactor
      - REDIS_URL=redis://redis:6379
      - S3_BUCKET=${S3_BUCKET:-dalston-artifacts}
      - S3_REGION=${S3_REGION:-us-east-1}
      - S3_ENDPOINT_URL=http://minio:9000
      - AWS_ACCESS_KEY_ID=${MINIO_ROOT_USER:-minioadmin}
      - AWS_SECRET_ACCESS_KEY=${MINIO_ROOT_PASSWORD:-minioadmin}
      - LOG_LEVEL=${LOG_LEVEL:-INFO}
      - LOG_FORMAT=${LOG_FORMAT:-json}
      # Prometheus metrics (M20)
      - METRICS_ENABLED=${METRICS_ENABLED:-true}
      - METRICS_PORT=9100
    depends_on:
      redis:
        condition: service_healthy
      minio-init:
        condition: service_completed_successfully
    restart: unless-stopped

  # --- MERGE STAGE ---
  stt-batch-merge:
    image: dalston/stt-batch-merge:latest
    build:
      context: .
      dockerfile: engines/merge/final-merger/Dockerfile
    environment:
      - ENGINE_ID=final-merger
      - REDIS_URL=redis://redis:6379
      - S3_BUCKET=${S3_BUCKET:-dalston-artifacts}
      - S3_REGION=${S3_REGION:-us-east-1}
      - S3_ENDPOINT_URL=http://minio:9000
      - AWS_ACCESS_KEY_ID=${MINIO_ROOT_USER:-minioadmin}
      - AWS_SECRET_ACCESS_KEY=${MINIO_ROOT_PASSWORD:-minioadmin}
      - LOG_LEVEL=${LOG_LEVEL:-INFO}
      - LOG_FORMAT=${LOG_FORMAT:-json}
      - OTEL_ENABLED=${OTEL_ENABLED:-false}
      - OTEL_EXPORTER_OTLP_ENDPOINT=${OTEL_EXPORTER_OTLP_ENDPOINT:-http://jaeger:4317}
      # Prometheus metrics (M20)
      - METRICS_ENABLED=${METRICS_ENABLED:-true}
      - METRICS_PORT=9100
    depends_on:
      redis:
        condition: service_healthy
      minio-init:
        condition: service_completed_successfully
    restart: unless-stopped

  # ============================================================
  # REALTIME STT WORKERS
  # ============================================================
  # Default: Parakeet CPU (local dev) - scale with: docker compose up -d --scale stt-rt-transcribe-parakeet-cpu=2
  # Whisper CPU: docker compose --profile whisper up -d
  # GPU workers: docker compose --profile gpu up -d

  # --- PARAKEET REALTIME (CPU - DEFAULT) ---
  # Default realtime worker for local development
  stt-rt-transcribe-parakeet-cpu:
    image: dalston/stt-rt-transcribe-parakeet:cpu
    build:
      context: .
      dockerfile: engines/realtime/parakeet-streaming/Dockerfile
      args:
        DEVICE: cpu
    environment:
      - WORKER_PORT=9000
      - MAX_SESSIONS=2
      - REDIS_URL=redis://redis:6379
      - LOG_LEVEL=${LOG_LEVEL:-INFO}
      - LOG_FORMAT=${LOG_FORMAT:-json}
      # S3 storage for audio/transcript persistence (M24)
      - S3_BUCKET=${S3_BUCKET:-dalston-artifacts}
      - S3_REGION=${S3_REGION:-us-east-1}
      - S3_ENDPOINT_URL=http://minio:9000
      - AWS_ACCESS_KEY_ID=${AWS_ACCESS_KEY_ID:-minioadmin}
      - AWS_SECRET_ACCESS_KEY=${AWS_SECRET_ACCESS_KEY:-minioadmin}
      - OTEL_ENABLED=${OTEL_ENABLED:-false}
      - OTEL_EXPORTER_OTLP_ENDPOINT=${OTEL_EXPORTER_OTLP_ENDPOINT:-http://jaeger:4317}
      # Prometheus metrics (M20)
      - METRICS_ENABLED=${METRICS_ENABLED:-true}
      - METRICS_PORT=9100
    volumes:
      - parakeet-models:/models
    depends_on:
      redis:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "python", "-c", "import socket; s=socket.socket(); s.settimeout(2); s.connect(('localhost', 9000)); s.close()"]
      interval: 10s
      timeout: 5s
      retries: 3
    restart: unless-stopped

  # Parakeet realtime (GPU - use with: docker compose --profile gpu up -d)
  stt-rt-transcribe-parakeet:
    image: dalston/stt-rt-transcribe-parakeet:latest
    build:
      context: .
      dockerfile: engines/realtime/parakeet-streaming/Dockerfile
    environment:
      - WORKER_PORT=9000
      - MAX_SESSIONS=4
      - REDIS_URL=redis://redis:6379
      - LOG_LEVEL=${LOG_LEVEL:-INFO}
      - LOG_FORMAT=${LOG_FORMAT:-json}
      # S3 storage for audio/transcript persistence (M24)
      - S3_BUCKET=${S3_BUCKET:-dalston-artifacts}
      - S3_REGION=${S3_REGION:-us-east-1}
      - S3_ENDPOINT_URL=${S3_ENDPOINT_URL:-http://minio:9000}
      - AWS_ACCESS_KEY_ID=${AWS_ACCESS_KEY_ID:-minioadmin}
      - AWS_SECRET_ACCESS_KEY=${AWS_SECRET_ACCESS_KEY:-minioadmin}
      - OTEL_ENABLED=${OTEL_ENABLED:-false}
      - OTEL_EXPORTER_OTLP_ENDPOINT=${OTEL_EXPORTER_OTLP_ENDPOINT:-http://jaeger:4317}
      # Prometheus metrics (M20)
      - METRICS_ENABLED=${METRICS_ENABLED:-true}
      - METRICS_PORT=9100
    volumes:
      - parakeet-models:/models
    depends_on:
      redis:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "python", "-c", "import socket; s=socket.socket(); s.settimeout(2); s.connect(('localhost', 9000)); s.close()"]
      interval: 10s
      timeout: 5s
      retries: 3
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
    profiles:
      - gpu
    restart: unless-stopped

  # --- WHISPER REALTIME (CPU) ---
  # Use with: docker compose --profile whisper up -d
  stt-rt-transcribe-whisper-cpu:
    image: dalston/stt-rt-transcribe-whisper:latest
    build:
      context: .
      dockerfile: engines/realtime/whisper-streaming/Dockerfile
    environment:
      - WORKER_PORT=9000
      - MAX_SESSIONS=4
      - REDIS_URL=redis://redis:6379
      - LOG_LEVEL=${LOG_LEVEL:-INFO}
      - LOG_FORMAT=${LOG_FORMAT:-json}
      # S3 storage for audio/transcript persistence (M24)
      - S3_BUCKET=${S3_BUCKET:-dalston-artifacts}
      - S3_REGION=${S3_REGION:-us-east-1}
      - S3_ENDPOINT_URL=http://minio:9000
      - AWS_ACCESS_KEY_ID=${AWS_ACCESS_KEY_ID:-minioadmin}
      - AWS_SECRET_ACCESS_KEY=${AWS_SECRET_ACCESS_KEY:-minioadmin}
      - OTEL_ENABLED=${OTEL_ENABLED:-false}
      - OTEL_EXPORTER_OTLP_ENDPOINT=${OTEL_EXPORTER_OTLP_ENDPOINT:-http://jaeger:4317}
      # Prometheus metrics (M20)
      - METRICS_ENABLED=${METRICS_ENABLED:-true}
      - METRICS_PORT=9100
    volumes:
      - realtime-models:/models
    depends_on:
      redis:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "python", "-c", "import socket; s=socket.socket(); s.settimeout(2); s.connect(('localhost', 9000)); s.close()"]
      interval: 10s
      timeout: 5s
      retries: 3
    profiles:
      - whisper
    restart: unless-stopped

  # Whisper realtime (GPU - use with: docker compose --profile gpu up -d)
  stt-rt-transcribe-whisper:
    image: dalston/stt-rt-transcribe-whisper:latest
    environment:
      - WORKER_PORT=9000
      - MAX_SESSIONS=4
      - REDIS_URL=redis://redis:6379
      - LOG_LEVEL=${LOG_LEVEL:-INFO}
      - LOG_FORMAT=${LOG_FORMAT:-json}
      # S3 storage for audio/transcript persistence (M24)
      - S3_BUCKET=${S3_BUCKET:-dalston-artifacts}
      - S3_REGION=${S3_REGION:-us-east-1}
      - S3_ENDPOINT_URL=${S3_ENDPOINT_URL:-http://minio:9000}
      - AWS_ACCESS_KEY_ID=${AWS_ACCESS_KEY_ID:-minioadmin}
      - AWS_SECRET_ACCESS_KEY=${AWS_SECRET_ACCESS_KEY:-minioadmin}
      - OTEL_ENABLED=${OTEL_ENABLED:-false}
      - OTEL_EXPORTER_OTLP_ENDPOINT=${OTEL_EXPORTER_OTLP_ENDPOINT:-http://jaeger:4317}
      # Prometheus metrics (M20)
      - METRICS_ENABLED=${METRICS_ENABLED:-true}
      - METRICS_PORT=9100
    volumes:
      - realtime-models:/models
    depends_on:
      redis:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "python", "-c", "import socket; s=socket.socket(); s.settimeout(2); s.connect(('localhost', 9000)); s.close()"]
      interval: 10s
      timeout: 5s
      retries: 3
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
    profiles:
      - gpu
    restart: unless-stopped

volumes:
  postgres-data:
  minio-data:
  whisper-models:
  align-models:
  pyannote-models:
  realtime-models:
  parakeet-models:
  gliner-models:
  prometheus-data:
  grafana-data:
