# Dalston - Modular Audio Transcription Server
#
# Image Sharing Strategy:
#   Services that use the same Dockerfile share a single image via the `image:` directive.
#   Only the first service has a `build:` section; others just reference the image.
#   This saves disk space and ensures consistency.
#
# Usage:
#   docker compose up -d
#   docker compose up -d --scale engine-faster-whisper=2  # scale specific engine

services:
  # ============================================================
  # INFRASTRUCTURE
  # ============================================================

  postgres:
    image: postgres:16-alpine
    environment:
      POSTGRES_USER: dalston
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD:-password}
      POSTGRES_DB: dalston
    ports:
      - "5432:5432"
    volumes:
      - postgres-data:/var/lib/postgresql/data
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U dalston"]
      interval: 5s
      timeout: 5s
      retries: 5
    restart: unless-stopped

  redis:
    image: redis:7-alpine
    command: redis-server --appendonly no
    ports:
      - "6379:6379"
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 5s
      timeout: 5s
      retries: 5
    restart: unless-stopped

  minio:
    image: minio/minio:latest
    command: server /data --console-address ":9001"
    environment:
      MINIO_ROOT_USER: ${MINIO_ROOT_USER:-minioadmin}
      MINIO_ROOT_PASSWORD: ${MINIO_ROOT_PASSWORD:-minioadmin}
    ports:
      - "9000:9000"
      - "9001:9001"
    volumes:
      - minio-data:/data
    healthcheck:
      test: ["CMD", "mc", "ready", "local"]
      interval: 5s
      timeout: 5s
      retries: 5
    restart: unless-stopped

  # Initialize MinIO bucket before gateway starts
  minio-init:
    image: minio/mc:latest
    depends_on:
      minio:
        condition: service_healthy
    entrypoint: >
      /bin/sh -c "
      mc alias set dalston http://minio:9000 $${MINIO_ROOT_USER:-minioadmin} $${MINIO_ROOT_PASSWORD:-minioadmin};
      mc mb dalston/$${S3_BUCKET:-dalston-artifacts} --ignore-existing;
      exit 0;
      "
    environment:
      MINIO_ROOT_USER: ${MINIO_ROOT_USER:-minioadmin}
      MINIO_ROOT_PASSWORD: ${MINIO_ROOT_PASSWORD:-minioadmin}
      S3_BUCKET: ${S3_BUCKET:-dalston-artifacts}

  # Jaeger for distributed tracing (M19)
  # Enable with: docker compose --profile tracing up -d
  # UI available at: http://localhost:16686
  jaeger:
    image: jaegertracing/all-in-one:1.54
    ports:
      - "16686:16686"  # Jaeger UI
      - "4317:4317"    # OTLP gRPC receiver
      - "4318:4318"    # OTLP HTTP receiver
    environment:
      - COLLECTOR_OTLP_ENABLED=true
    profiles:
      - tracing
    restart: unless-stopped

  # Prometheus for metrics collection (M20)
  # Enable with: docker compose --profile monitoring up -d
  # UI available at: http://localhost:9090
  prometheus:
    image: prom/prometheus:v2.50.0
    volumes:
      - ./docker/prometheus/prometheus.yml:/etc/prometheus/prometheus.yml:ro
      - prometheus-data:/prometheus
    ports:
      - "9090:9090"
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--web.enable-lifecycle'
      - '--storage.tsdb.retention.time=1d'
      - '--storage.tsdb.retention.size=500MB'
    profiles:
      - monitoring
    restart: unless-stopped

  # Grafana for dashboards (M20)
  # Enable with: docker compose --profile monitoring up -d
  # UI available at: http://localhost:3001 (admin/dalston)
  grafana:
    image: grafana/grafana:10.3.0
    volumes:
      - ./docker/grafana/provisioning:/etc/grafana/provisioning:ro
      - ./docker/grafana/dashboards:/var/lib/grafana/dashboards:ro
      - grafana-data:/var/lib/grafana
    ports:
      - "3001:3000"
    environment:
      - GF_SECURITY_ADMIN_PASSWORD=dalston
      - GF_AUTH_ANONYMOUS_ENABLED=true
      - GF_AUTH_ANONYMOUS_ORG_ROLE=Viewer
      - GF_DASHBOARDS_DEFAULT_HOME_DASHBOARD_PATH=/var/lib/grafana/dashboards/dalston-overview.json
    depends_on:
      - prometheus
    profiles:
      - monitoring
    restart: unless-stopped

  # Metrics exporter for Redis queue depths (M20)
  # Enable with: docker compose --profile monitoring up -d
  metrics-exporter:
    image: dalston/gateway:latest
    command: python -m dalston.metrics_exporter
    environment:
      - REDIS_URL=redis://redis:6379
      - METRICS_PORT=9100
      - SCRAPE_INTERVAL=15
      - LOG_LEVEL=${LOG_LEVEL:-INFO}
      - LOG_FORMAT=${LOG_FORMAT:-json}
    depends_on:
      redis:
        condition: service_healthy
    profiles:
      - monitoring
    restart: unless-stopped

  # ============================================================
  # CORE SERVICES
  # ============================================================

  gateway:
    image: dalston/gateway:latest
    build:
      context: .
      dockerfile: docker/Dockerfile.gateway
    ports:
      - "8000:8000"
    profiles:
      - prod
    environment:
      - DATABASE_URL=postgresql+asyncpg://dalston:${POSTGRES_PASSWORD:-password}@postgres:5432/dalston
      - REDIS_URL=redis://redis:6379
      - S3_BUCKET=${S3_BUCKET:-dalston-artifacts}
      - S3_REGION=${S3_REGION:-us-east-1}
      - S3_ENDPOINT_URL=http://minio:9000
      - AWS_ACCESS_KEY_ID=${MINIO_ROOT_USER:-minioadmin}
      - AWS_SECRET_ACCESS_KEY=${MINIO_ROOT_PASSWORD:-minioadmin}
      - LOG_LEVEL=${LOG_LEVEL:-INFO}
      - LOG_FORMAT=${LOG_FORMAT:-json}
      # Distributed tracing (M19) - enable with OTEL_ENABLED=true
      - OTEL_ENABLED=${OTEL_ENABLED:-false}
      - OTEL_EXPORTER_OTLP_ENDPOINT=${OTEL_EXPORTER_OTLP_ENDPOINT:-http://jaeger:4317}
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
      minio-init:
        condition: service_completed_successfully
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 10s
      timeout: 5s
      retries: 5
    restart: unless-stopped

  orchestrator:
    image: dalston/orchestrator:latest
    build:
      context: .
      dockerfile: docker/Dockerfile.orchestrator
    profiles:
      - prod
    environment:
      - DATABASE_URL=postgresql+asyncpg://dalston:${POSTGRES_PASSWORD:-password}@postgres:5432/dalston
      - REDIS_URL=redis://redis:6379
      - S3_BUCKET=${S3_BUCKET:-dalston-artifacts}
      - S3_REGION=${S3_REGION:-us-east-1}
      - S3_ENDPOINT_URL=http://minio:9000
      - AWS_ACCESS_KEY_ID=${MINIO_ROOT_USER:-minioadmin}
      - AWS_SECRET_ACCESS_KEY=${MINIO_ROOT_PASSWORD:-minioadmin}
      - LOG_LEVEL=${LOG_LEVEL:-INFO}
      - LOG_FORMAT=${LOG_FORMAT:-json}
      # Distributed tracing (M19) - enable with OTEL_ENABLED=true
      - OTEL_ENABLED=${OTEL_ENABLED:-false}
      - OTEL_EXPORTER_OTLP_ENDPOINT=${OTEL_EXPORTER_OTLP_ENDPOINT:-http://jaeger:4317}
      # Prometheus metrics (M20) - enabled by default
      - METRICS_ENABLED=${METRICS_ENABLED:-true}
      - METRICS_PORT=8001
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
    restart: unless-stopped

  # ============================================================
  # ENGINES (M02+)
  # ============================================================

  engine-audio-prepare:
    image: dalston/engine-audio-prepare:latest
    build:
      context: .
      dockerfile: engines/prepare/audio-prepare/Dockerfile
    environment:
      - ENGINE_ID=audio-prepare
      - REDIS_URL=redis://redis:6379
      - S3_BUCKET=${S3_BUCKET:-dalston-artifacts}
      - S3_REGION=${S3_REGION:-us-east-1}
      - S3_ENDPOINT_URL=http://minio:9000
      - AWS_ACCESS_KEY_ID=${MINIO_ROOT_USER:-minioadmin}
      - AWS_SECRET_ACCESS_KEY=${MINIO_ROOT_PASSWORD:-minioadmin}
      - LOG_LEVEL=${LOG_LEVEL:-INFO}
      - LOG_FORMAT=${LOG_FORMAT:-json}
      - OTEL_ENABLED=${OTEL_ENABLED:-false}
      - OTEL_EXPORTER_OTLP_ENDPOINT=${OTEL_EXPORTER_OTLP_ENDPOINT:-http://jaeger:4317}
      # Prometheus metrics (M20)
      - METRICS_ENABLED=${METRICS_ENABLED:-true}
      - METRICS_PORT=9100
    depends_on:
      redis:
        condition: service_healthy
      minio-init:
        condition: service_completed_successfully
    restart: unless-stopped

  engine-faster-whisper:
    image: dalston/engine-faster-whisper:latest
    build:
      context: .
      dockerfile: engines/transcribe/faster-whisper/Dockerfile
    environment:
      - ENGINE_ID=faster-whisper
      - REDIS_URL=redis://redis:6379
      - S3_BUCKET=${S3_BUCKET:-dalston-artifacts}
      - S3_REGION=${S3_REGION:-us-east-1}
      - S3_ENDPOINT_URL=http://minio:9000
      - AWS_ACCESS_KEY_ID=${MINIO_ROOT_USER:-minioadmin}
      - AWS_SECRET_ACCESS_KEY=${MINIO_ROOT_PASSWORD:-minioadmin}
      - LOG_LEVEL=${LOG_LEVEL:-INFO}
      - LOG_FORMAT=${LOG_FORMAT:-json}
      - OTEL_ENABLED=${OTEL_ENABLED:-false}
      - OTEL_EXPORTER_OTLP_ENDPOINT=${OTEL_EXPORTER_OTLP_ENDPOINT:-http://jaeger:4317}
      # Prometheus metrics (M20)
      - METRICS_ENABLED=${METRICS_ENABLED:-true}
      - METRICS_PORT=9100
    volumes:
      - whisper-models:/models
    depends_on:
      redis:
        condition: service_healthy
      minio-init:
        condition: service_completed_successfully
    restart: unless-stopped

  # GPU-accelerated faster-whisper (use with: docker compose --profile gpu up -d)
  # Shares image with engine-faster-whisper
  engine-faster-whisper-gpu:
    image: dalston/engine-faster-whisper:latest
    environment:
      - ENGINE_ID=faster-whisper
      - REDIS_URL=redis://redis:6379
      - S3_BUCKET=${S3_BUCKET:-dalston-artifacts}
      - S3_REGION=${S3_REGION:-us-east-1}
      - S3_ENDPOINT_URL=http://minio:9000
      - AWS_ACCESS_KEY_ID=${MINIO_ROOT_USER:-minioadmin}
      - AWS_SECRET_ACCESS_KEY=${MINIO_ROOT_PASSWORD:-minioadmin}
      - LOG_LEVEL=${LOG_LEVEL:-INFO}
      - LOG_FORMAT=${LOG_FORMAT:-json}
    volumes:
      - whisper-models:/models
    depends_on:
      redis:
        condition: service_healthy
      minio-init:
        condition: service_completed_successfully
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
    profiles:
      - gpu
    restart: unless-stopped

  engine-whisperx-align:
    image: dalston/engine-whisperx-align:latest
    build:
      context: .
      dockerfile: engines/align/whisperx-align/Dockerfile
    environment:
      - ENGINE_ID=whisperx-align
      - REDIS_URL=redis://redis:6379
      - S3_BUCKET=${S3_BUCKET:-dalston-artifacts}
      - S3_REGION=${S3_REGION:-us-east-1}
      - S3_ENDPOINT_URL=http://minio:9000
      - AWS_ACCESS_KEY_ID=${MINIO_ROOT_USER:-minioadmin}
      - AWS_SECRET_ACCESS_KEY=${MINIO_ROOT_PASSWORD:-minioadmin}
      - LOG_LEVEL=${LOG_LEVEL:-INFO}
      - LOG_FORMAT=${LOG_FORMAT:-json}
      - OTEL_ENABLED=${OTEL_ENABLED:-false}
      - OTEL_EXPORTER_OTLP_ENDPOINT=${OTEL_EXPORTER_OTLP_ENDPOINT:-http://jaeger:4317}
      # Prometheus metrics (M20)
      - METRICS_ENABLED=${METRICS_ENABLED:-true}
      - METRICS_PORT=9100
    volumes:
      - align-models:/models
    depends_on:
      redis:
        condition: service_healthy
      minio-init:
        condition: service_completed_successfully
    restart: unless-stopped

  # GPU-accelerated whisperx-align (use with: docker compose --profile gpu up -d)
  # Shares image with engine-whisperx-align
  engine-whisperx-align-gpu:
    image: dalston/engine-whisperx-align:latest
    environment:
      - ENGINE_ID=whisperx-align
      - REDIS_URL=redis://redis:6379
      - S3_BUCKET=${S3_BUCKET:-dalston-artifacts}
      - S3_REGION=${S3_REGION:-us-east-1}
      - S3_ENDPOINT_URL=http://minio:9000
      - AWS_ACCESS_KEY_ID=${MINIO_ROOT_USER:-minioadmin}
      - AWS_SECRET_ACCESS_KEY=${MINIO_ROOT_PASSWORD:-minioadmin}
      - LOG_LEVEL=${LOG_LEVEL:-INFO}
      - LOG_FORMAT=${LOG_FORMAT:-json}
      - OTEL_ENABLED=${OTEL_ENABLED:-false}
      - OTEL_EXPORTER_OTLP_ENDPOINT=${OTEL_EXPORTER_OTLP_ENDPOINT:-http://jaeger:4317}
    volumes:
      - align-models:/models
    depends_on:
      redis:
        condition: service_healthy
      minio-init:
        condition: service_completed_successfully
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
    profiles:
      - gpu
    restart: unless-stopped

  engine-final-merger:
    image: dalston/engine-final-merger:latest
    build:
      context: .
      dockerfile: engines/merge/final-merger/Dockerfile
    environment:
      - ENGINE_ID=final-merger
      - REDIS_URL=redis://redis:6379
      - S3_BUCKET=${S3_BUCKET:-dalston-artifacts}
      - S3_REGION=${S3_REGION:-us-east-1}
      - S3_ENDPOINT_URL=http://minio:9000
      - AWS_ACCESS_KEY_ID=${MINIO_ROOT_USER:-minioadmin}
      - AWS_SECRET_ACCESS_KEY=${MINIO_ROOT_PASSWORD:-minioadmin}
      - LOG_LEVEL=${LOG_LEVEL:-INFO}
      - LOG_FORMAT=${LOG_FORMAT:-json}
      - OTEL_ENABLED=${OTEL_ENABLED:-false}
      - OTEL_EXPORTER_OTLP_ENDPOINT=${OTEL_EXPORTER_OTLP_ENDPOINT:-http://jaeger:4317}
      # Prometheus metrics (M20)
      - METRICS_ENABLED=${METRICS_ENABLED:-true}
      - METRICS_PORT=9100
    depends_on:
      redis:
        condition: service_healthy
      minio-init:
        condition: service_completed_successfully
    restart: unless-stopped

  # ============================================================
  # PARAKEET ENGINES (M22)
  # ============================================================

  # NVIDIA Parakeet batch transcription engine (GPU)
  engine-parakeet:
    image: dalston/engine-parakeet:latest
    build:
      context: .
      dockerfile: engines/transcribe/parakeet/Dockerfile
    environment:
      - ENGINE_ID=parakeet
      - REDIS_URL=redis://redis:6379
      - S3_BUCKET=${S3_BUCKET:-dalston-artifacts}
      - S3_REGION=${S3_REGION:-us-east-1}
      - S3_ENDPOINT_URL=http://minio:9000
      - AWS_ACCESS_KEY_ID=${MINIO_ROOT_USER:-minioadmin}
      - AWS_SECRET_ACCESS_KEY=${MINIO_ROOT_PASSWORD:-minioadmin}
      - LOG_LEVEL=${LOG_LEVEL:-INFO}
      - LOG_FORMAT=${LOG_FORMAT:-json}
      # Prometheus metrics (M20)
      - METRICS_ENABLED=${METRICS_ENABLED:-true}
      - METRICS_PORT=9100
    volumes:
      - parakeet-models:/models
    depends_on:
      redis:
        condition: service_healthy
      minio-init:
        condition: service_completed_successfully
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
    profiles:
      - gpu
      - parakeet
    restart: unless-stopped

  # NVIDIA Parakeet batch transcription engine (CPU - for local dev)
  engine-parakeet-cpu:
    image: dalston/engine-parakeet:cpu
    build:
      context: .
      dockerfile: engines/transcribe/parakeet/Dockerfile
      args:
        DEVICE: cpu
    environment:
      - ENGINE_ID=parakeet
      - REDIS_URL=redis://redis:6379
      - S3_BUCKET=${S3_BUCKET:-dalston-artifacts}
      - S3_REGION=${S3_REGION:-us-east-1}
      - S3_ENDPOINT_URL=http://minio:9000
      - AWS_ACCESS_KEY_ID=${MINIO_ROOT_USER:-minioadmin}
      - AWS_SECRET_ACCESS_KEY=${MINIO_ROOT_PASSWORD:-minioadmin}
      - LOG_LEVEL=${LOG_LEVEL:-INFO}
      - LOG_FORMAT=${LOG_FORMAT:-json}
      # Prometheus metrics (M20)
      - METRICS_ENABLED=${METRICS_ENABLED:-true}
      - METRICS_PORT=9100
    volumes:
      - parakeet-models:/models
    depends_on:
      redis:
        condition: service_healthy
      minio-init:
        condition: service_completed_successfully
    profiles:
      - parakeet-cpu
    restart: unless-stopped

  # ============================================================
  # PII DETECTION & AUDIO REDACTION ENGINES (M26)
  # ============================================================

  engine-pii-presidio:
    image: dalston/engine-pii-presidio:latest
    build:
      context: .
      dockerfile: engines/detect/pii-presidio/Dockerfile
    environment:
      - ENGINE_ID=pii-presidio
      - REDIS_URL=redis://redis:6379
      - S3_BUCKET=${S3_BUCKET:-dalston-artifacts}
      - S3_REGION=${S3_REGION:-us-east-1}
      - S3_ENDPOINT_URL=http://minio:9000
      - AWS_ACCESS_KEY_ID=${MINIO_ROOT_USER:-minioadmin}
      - AWS_SECRET_ACCESS_KEY=${MINIO_ROOT_PASSWORD:-minioadmin}
      - LOG_LEVEL=${LOG_LEVEL:-INFO}
      - LOG_FORMAT=${LOG_FORMAT:-json}
      # Prometheus metrics (M20)
      - METRICS_ENABLED=${METRICS_ENABLED:-true}
      - METRICS_PORT=9100
    volumes:
      - gliner-models:/models
    depends_on:
      redis:
        condition: service_healthy
      minio-init:
        condition: service_completed_successfully
    restart: unless-stopped

  engine-audio-redactor:
    image: dalston/engine-audio-redactor:latest
    build:
      context: .
      dockerfile: engines/redact/audio-redactor/Dockerfile
    environment:
      - ENGINE_ID=audio-redactor
      - REDIS_URL=redis://redis:6379
      - S3_BUCKET=${S3_BUCKET:-dalston-artifacts}
      - S3_REGION=${S3_REGION:-us-east-1}
      - S3_ENDPOINT_URL=http://minio:9000
      - AWS_ACCESS_KEY_ID=${MINIO_ROOT_USER:-minioadmin}
      - AWS_SECRET_ACCESS_KEY=${MINIO_ROOT_PASSWORD:-minioadmin}
      - LOG_LEVEL=${LOG_LEVEL:-INFO}
      - LOG_FORMAT=${LOG_FORMAT:-json}
      # Prometheus metrics (M20)
      - METRICS_ENABLED=${METRICS_ENABLED:-true}
      - METRICS_PORT=9100
    depends_on:
      redis:
        condition: service_healthy
      minio-init:
        condition: service_completed_successfully
    restart: unless-stopped

  # ============================================================
  # DIARIZATION ENGINES (M04)
  # ============================================================

  engine-pyannote-3.1:
    image: dalston/engine-pyannote-3.1:latest
    build:
      context: .
      dockerfile: engines/diarize/pyannote-3.1/Dockerfile
    environment:
      - ENGINE_ID=pyannote-3.1
      - REDIS_URL=redis://redis:6379
      - S3_BUCKET=${S3_BUCKET:-dalston-artifacts}
      - S3_REGION=${S3_REGION:-us-east-1}
      - S3_ENDPOINT_URL=http://minio:9000
      - AWS_ACCESS_KEY_ID=${MINIO_ROOT_USER:-minioadmin}
      - AWS_SECRET_ACCESS_KEY=${MINIO_ROOT_PASSWORD:-minioadmin}
      - HF_TOKEN=${HF_TOKEN:-}
      - DIARIZATION_DISABLED=${DIARIZATION_DISABLED:-false}
      - LOG_LEVEL=${LOG_LEVEL:-INFO}
      - LOG_FORMAT=${LOG_FORMAT:-json}
      # Prometheus metrics (M20)
      - METRICS_ENABLED=${METRICS_ENABLED:-true}
      - METRICS_PORT=9100
    volumes:
      - pyannote-models:/models
    depends_on:
      redis:
        condition: service_healthy
      minio-init:
        condition: service_completed_successfully
    restart: unless-stopped

  # GPU-accelerated pyannote (use with: docker compose --profile gpu up -d)
  # Shares image with engine-pyannote-3.1
  engine-pyannote-3.1-gpu:
    image: dalston/engine-pyannote-3.1:latest
    environment:
      - ENGINE_ID=pyannote-3.1
      - REDIS_URL=redis://redis:6379
      - S3_BUCKET=${S3_BUCKET:-dalston-artifacts}
      - S3_REGION=${S3_REGION:-us-east-1}
      - S3_ENDPOINT_URL=http://minio:9000
      - AWS_ACCESS_KEY_ID=${MINIO_ROOT_USER:-minioadmin}
      - AWS_SECRET_ACCESS_KEY=${MINIO_ROOT_PASSWORD:-minioadmin}
      - HF_TOKEN=${HF_TOKEN:-}
      - LOG_LEVEL=${LOG_LEVEL:-INFO}
      - LOG_FORMAT=${LOG_FORMAT:-json}
    volumes:
      - pyannote-models:/models
    depends_on:
      redis:
        condition: service_healthy
      minio-init:
        condition: service_completed_successfully
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
    profiles:
      - gpu
    restart: unless-stopped

  # Pyannote 4.0 with Community-1 pipeline and VBx clustering
  engine-pyannote-4.0:
    image: dalston/engine-pyannote-4.0:latest
    build:
      context: .
      dockerfile: engines/diarize/pyannote-4.0/Dockerfile
    environment:
      - ENGINE_ID=pyannote-4.0
      - REDIS_URL=redis://redis:6379
      - S3_BUCKET=${S3_BUCKET:-dalston-artifacts}
      - S3_REGION=${S3_REGION:-us-east-1}
      - S3_ENDPOINT_URL=http://minio:9000
      - AWS_ACCESS_KEY_ID=${MINIO_ROOT_USER:-minioadmin}
      - AWS_SECRET_ACCESS_KEY=${MINIO_ROOT_PASSWORD:-minioadmin}
      - HF_TOKEN=${HF_TOKEN:-}
      - DIARIZATION_DISABLED=${DIARIZATION_DISABLED:-false}
      - LOG_LEVEL=${LOG_LEVEL:-INFO}
      - LOG_FORMAT=${LOG_FORMAT:-json}
      # Prometheus metrics (M20)
      - METRICS_ENABLED=${METRICS_ENABLED:-true}
      - METRICS_PORT=9100
    volumes:
      - pyannote-models:/models
    depends_on:
      redis:
        condition: service_healthy
      minio-init:
        condition: service_completed_successfully
    restart: unless-stopped

  # GPU-accelerated pyannote 4.0 (use with: docker compose --profile gpu up -d)
  # Shares image with engine-pyannote-4.0
  engine-pyannote-4.0-gpu:
    image: dalston/engine-pyannote-4.0:latest
    environment:
      - ENGINE_ID=pyannote-4.0
      - REDIS_URL=redis://redis:6379
      - S3_BUCKET=${S3_BUCKET:-dalston-artifacts}
      - S3_REGION=${S3_REGION:-us-east-1}
      - S3_ENDPOINT_URL=http://minio:9000
      - AWS_ACCESS_KEY_ID=${MINIO_ROOT_USER:-minioadmin}
      - AWS_SECRET_ACCESS_KEY=${MINIO_ROOT_PASSWORD:-minioadmin}
      - HF_TOKEN=${HF_TOKEN:-}
      - LOG_LEVEL=${LOG_LEVEL:-INFO}
      - LOG_FORMAT=${LOG_FORMAT:-json}
    volumes:
      - pyannote-models:/models
    depends_on:
      redis:
        condition: service_healthy
      minio-init:
        condition: service_completed_successfully
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
    profiles:
      - gpu
    restart: unless-stopped

  # ============================================================
  # REALTIME ENGINES (M06)
  # All realtime workers share the same image (dalston/realtime-whisper)
  # ============================================================

  realtime-whisper-1:
    image: dalston/realtime-whisper:latest
    build:
      context: .
      dockerfile: engines/realtime/whisper-streaming/Dockerfile
    environment:
      - WORKER_ID=realtime-whisper-1
      - WORKER_PORT=9000
      - WORKER_ENDPOINT=ws://realtime-whisper-1:9000
      - MAX_SESSIONS=4
      - REDIS_URL=redis://redis:6379
      - LOG_LEVEL=${LOG_LEVEL:-INFO}
      - LOG_FORMAT=${LOG_FORMAT:-json}
      # S3 storage for audio/transcript persistence (M24)
      - S3_BUCKET=${S3_BUCKET:-dalston-artifacts}
      - S3_REGION=${S3_REGION:-us-east-1}
      - S3_ENDPOINT_URL=${S3_ENDPOINT_URL:-http://minio:9000}
      - AWS_ACCESS_KEY_ID=${AWS_ACCESS_KEY_ID:-minioadmin}
      - AWS_SECRET_ACCESS_KEY=${AWS_SECRET_ACCESS_KEY:-minioadmin}
      - OTEL_ENABLED=${OTEL_ENABLED:-false}
      - OTEL_EXPORTER_OTLP_ENDPOINT=${OTEL_EXPORTER_OTLP_ENDPOINT:-http://jaeger:4317}
      # Prometheus metrics (M20)
      - METRICS_ENABLED=${METRICS_ENABLED:-true}
      - METRICS_PORT=9100
    volumes:
      - realtime-models:/models
    depends_on:
      redis:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "python", "-c", "import socket; s=socket.socket(); s.settimeout(2); s.connect(('localhost', 9000)); s.close()"]
      interval: 10s
      timeout: 5s
      retries: 3
    restart: unless-stopped

  # Additional realtime worker - shares image with realtime-whisper-1
  realtime-whisper-2:
    image: dalston/realtime-whisper:latest
    environment:
      - WORKER_ID=realtime-whisper-2
      - WORKER_PORT=9000
      - WORKER_ENDPOINT=ws://realtime-whisper-2:9000
      - MAX_SESSIONS=4
      - REDIS_URL=redis://redis:6379
      - LOG_LEVEL=${LOG_LEVEL:-INFO}
      - LOG_FORMAT=${LOG_FORMAT:-json}
      # S3 storage for audio/transcript persistence (M24)
      - S3_BUCKET=${S3_BUCKET:-dalston-artifacts}
      - S3_REGION=${S3_REGION:-us-east-1}
      - S3_ENDPOINT_URL=${S3_ENDPOINT_URL:-http://minio:9000}
      - AWS_ACCESS_KEY_ID=${AWS_ACCESS_KEY_ID:-minioadmin}
      - AWS_SECRET_ACCESS_KEY=${AWS_SECRET_ACCESS_KEY:-minioadmin}
      # Prometheus metrics (M20)
      - METRICS_ENABLED=${METRICS_ENABLED:-true}
      - METRICS_PORT=9100
    volumes:
      - realtime-models:/models
    depends_on:
      redis:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "python", "-c", "import socket; s=socket.socket(); s.settimeout(2); s.connect(('localhost', 9000)); s.close()"]
      interval: 10s
      timeout: 5s
      retries: 3
    restart: unless-stopped

  # GPU-accelerated realtime worker (use with: docker compose --profile gpu up -d)
  # Shares image with realtime-whisper-1
  realtime-whisper-gpu:
    image: dalston/realtime-whisper:latest
    environment:
      - WORKER_ID=realtime-whisper-gpu
      - WORKER_PORT=9000
      - WORKER_ENDPOINT=ws://realtime-whisper-gpu:9000
      - MAX_SESSIONS=4
      - REDIS_URL=redis://redis:6379
      - LOG_LEVEL=${LOG_LEVEL:-INFO}
      - LOG_FORMAT=${LOG_FORMAT:-json}
      # S3 storage for audio/transcript persistence (M24)
      - S3_BUCKET=${S3_BUCKET:-dalston-artifacts}
      - S3_REGION=${S3_REGION:-us-east-1}
      - S3_ENDPOINT_URL=${S3_ENDPOINT_URL:-http://minio:9000}
      - AWS_ACCESS_KEY_ID=${AWS_ACCESS_KEY_ID:-minioadmin}
      - AWS_SECRET_ACCESS_KEY=${AWS_SECRET_ACCESS_KEY:-minioadmin}
    volumes:
      - realtime-models:/models
    depends_on:
      redis:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "python", "-c", "import socket; s=socket.socket(); s.settimeout(2); s.connect(('localhost', 9000)); s.close()"]
      interval: 10s
      timeout: 5s
      retries: 3
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
    profiles:
      - gpu
    restart: unless-stopped

  # ============================================================
  # PARAKEET REALTIME ENGINES (M22)
  # ============================================================

  # NVIDIA Parakeet streaming realtime worker (GPU)
  realtime-parakeet-1:
    image: dalston/realtime-parakeet:latest
    build:
      context: .
      dockerfile: engines/realtime/parakeet-streaming/Dockerfile
    environment:
      - WORKER_ID=realtime-parakeet-1
      - WORKER_PORT=9000
      - WORKER_ENDPOINT=ws://realtime-parakeet-1:9000
      - MAX_SESSIONS=4
      - REDIS_URL=redis://redis:6379
      - LOG_LEVEL=${LOG_LEVEL:-INFO}
      - LOG_FORMAT=${LOG_FORMAT:-json}
      # S3 storage for audio/transcript persistence (M24)
      - S3_BUCKET=${S3_BUCKET:-dalston-artifacts}
      - S3_REGION=${S3_REGION:-us-east-1}
      - S3_ENDPOINT_URL=${S3_ENDPOINT_URL:-http://minio:9000}
      - AWS_ACCESS_KEY_ID=${AWS_ACCESS_KEY_ID:-minioadmin}
      - AWS_SECRET_ACCESS_KEY=${AWS_SECRET_ACCESS_KEY:-minioadmin}
      # Prometheus metrics (M20)
      - METRICS_ENABLED=${METRICS_ENABLED:-true}
      - METRICS_PORT=9100
    volumes:
      - parakeet-models:/models
    depends_on:
      redis:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "python", "-c", "import socket; s=socket.socket(); s.settimeout(2); s.connect(('localhost', 9000)); s.close()"]
      interval: 10s
      timeout: 5s
      retries: 3
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
    profiles:
      - gpu
      - parakeet
    restart: unless-stopped

  # Additional Parakeet realtime worker (GPU)
  realtime-parakeet-2:
    image: dalston/realtime-parakeet:latest
    environment:
      - WORKER_ID=realtime-parakeet-2
      - WORKER_PORT=9000
      - WORKER_ENDPOINT=ws://realtime-parakeet-2:9000
      - MAX_SESSIONS=4
      - REDIS_URL=redis://redis:6379
      - LOG_LEVEL=${LOG_LEVEL:-INFO}
      - LOG_FORMAT=${LOG_FORMAT:-json}
      # S3 storage for audio/transcript persistence (M24)
      - S3_BUCKET=${S3_BUCKET:-dalston-artifacts}
      - S3_REGION=${S3_REGION:-us-east-1}
      - S3_ENDPOINT_URL=${S3_ENDPOINT_URL:-http://minio:9000}
      - AWS_ACCESS_KEY_ID=${AWS_ACCESS_KEY_ID:-minioadmin}
      - AWS_SECRET_ACCESS_KEY=${AWS_SECRET_ACCESS_KEY:-minioadmin}
      # Prometheus metrics (M20)
      - METRICS_ENABLED=${METRICS_ENABLED:-true}
      - METRICS_PORT=9100
    volumes:
      - parakeet-models:/models
    depends_on:
      redis:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "python", "-c", "import socket; s=socket.socket(); s.settimeout(2); s.connect(('localhost', 9000)); s.close()"]
      interval: 10s
      timeout: 5s
      retries: 3
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
    profiles:
      - gpu
      - parakeet
    restart: unless-stopped

  # NVIDIA Parakeet streaming realtime worker (CPU - for local dev)
  realtime-parakeet-cpu:
    image: dalston/realtime-parakeet:cpu
    build:
      context: .
      dockerfile: engines/realtime/parakeet-streaming/Dockerfile
      args:
        DEVICE: cpu
    environment:
      - WORKER_ID=realtime-parakeet-cpu
      - WORKER_PORT=9000
      - WORKER_ENDPOINT=ws://realtime-parakeet-cpu:9000
      - MAX_SESSIONS=2
      - REDIS_URL=redis://redis:6379
      - LOG_LEVEL=${LOG_LEVEL:-INFO}
      - LOG_FORMAT=${LOG_FORMAT:-json}
      # S3 storage for audio/transcript persistence (M24)
      # Note: Containers access MinIO via internal network, not localhost
      - S3_BUCKET=${S3_BUCKET:-dalston-artifacts}
      - S3_REGION=${S3_REGION:-us-east-1}
      - S3_ENDPOINT_URL=http://minio:9000
      - AWS_ACCESS_KEY_ID=${AWS_ACCESS_KEY_ID:-minioadmin}
      - AWS_SECRET_ACCESS_KEY=${AWS_SECRET_ACCESS_KEY:-minioadmin}
      # Prometheus metrics (M20)
      - METRICS_ENABLED=${METRICS_ENABLED:-true}
      - METRICS_PORT=9100
    volumes:
      - parakeet-models:/models
    depends_on:
      redis:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "python", "-c", "import socket; s=socket.socket(); s.settimeout(2); s.connect(('localhost', 9000)); s.close()"]
      interval: 10s
      timeout: 5s
      retries: 3
    profiles:
      - parakeet-cpu
    restart: unless-stopped

volumes:
  postgres-data:
  minio-data:
  whisper-models:
  align-models:
  pyannote-models:
  realtime-models:
  parakeet-models:
  gliner-models:
  prometheus-data:
  grafana-data:
